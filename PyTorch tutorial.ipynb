{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.i=nn.Linear(2,5)\n",
    "        self.l=nn.Linear(5,10)\n",
    "        self.l1=nn.Linear(10,1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.l1(self.l(self.i(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralNet()\n",
    "out=model.forward(torch.rand(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=torch.load(r'C:\\Users\\Aushim\\Google Drive\\' GoodNotes\\18667 Algorithms For Large Scale distributed ML\\HW3\\18667HW3\\HW3-prob6\\traindata')\n",
    "test_loader= torch.load(r'C:\\Users\\Aushim\\Google Drive\\' GoodNotes\\18667 Algorithms For Large Scale distributed ML\\HW3\\18667HW3\\HW3-prob6\\test_loader')\n",
    "dataratios= torch.load(r'C:\\Users\\Aushim\\Google Drive\\' GoodNotes\\18667 Algorithms For Large Scale distributed ML\\HW3\\18667HW3\\HW3-prob6\\dataratios')\n",
    "partition =torch.load(r'C:\\Users\\Aushim\\Google Drive\\' GoodNotes\\18667 Algorithms For Large Scale distributed ML\\HW3\\18667HW3\\HW3-prob6\\partition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "torch.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=criterion(out)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<generator object Module.parameters at 0x000002D9017D5D68>\n"
     ]
    }
   ],
   "source": [
    "m=model.parameters()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002D9017D5D68>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "m #generator uses 'yield' after a for loop, which basically returns a value in each for loop. Generators run 1 iteration of the for loop everytime they are called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0197,  0.4276],\n",
      "        [-0.3853, -0.0511],\n",
      "        [-0.4546,  0.3857],\n",
      "        [-0.0220, -0.6716],\n",
      "        [ 0.3855,  0.2678]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4125,  0.4195, -0.5047,  0.2852, -0.6187], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3708,  0.0031, -0.3170,  0.2373, -0.0396],\n",
      "        [ 0.0556,  0.2937,  0.1855, -0.2691,  0.1801],\n",
      "        [ 0.1217,  0.0841,  0.4051, -0.3729,  0.0954],\n",
      "        [ 0.3591, -0.0588, -0.2873,  0.1234, -0.2960],\n",
      "        [-0.3650, -0.1286, -0.2019,  0.1099, -0.1829],\n",
      "        [-0.2345,  0.2964,  0.2008,  0.1536, -0.3596],\n",
      "        [-0.0363,  0.0244, -0.0666, -0.2013,  0.3473],\n",
      "        [ 0.0407,  0.0947, -0.2300, -0.1252,  0.2743],\n",
      "        [-0.2055, -0.0200, -0.3946, -0.1247,  0.2620],\n",
      "        [-0.2680, -0.2256, -0.1557,  0.3557,  0.0820]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0174, -0.0418, -0.3103,  0.3874,  0.3733, -0.0120,  0.3958, -0.0426,\n",
      "        -0.2509, -0.1188], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0634,  0.2221, -0.1416,  0.1017, -0.1207,  0.0477, -0.2734, -0.1802,\n",
      "          0.2154, -0.0621]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1163], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in m:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'weight'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5ec693afc935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#i,l,l1 are all the layer names defined in the model above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i.weight) #i,l,l1 are all the layer names defined in the model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('i.weight', Parameter containing:\n",
      "tensor([[-0.0197,  0.4276],\n",
      "        [-0.3853, -0.0511],\n",
      "        [-0.4546,  0.3857],\n",
      "        [-0.0220, -0.6716],\n",
      "        [ 0.3855,  0.2678]], requires_grad=True))\n",
      "('i.bias', Parameter containing:\n",
      "tensor([-0.4125,  0.4195, -0.5047,  0.2852, -0.6187], requires_grad=True))\n",
      "('l.weight', Parameter containing:\n",
      "tensor([[-0.3708,  0.0031, -0.3170,  0.2373, -0.0396],\n",
      "        [ 0.0556,  0.2937,  0.1855, -0.2691,  0.1801],\n",
      "        [ 0.1217,  0.0841,  0.4051, -0.3729,  0.0954],\n",
      "        [ 0.3591, -0.0588, -0.2873,  0.1234, -0.2960],\n",
      "        [-0.3650, -0.1286, -0.2019,  0.1099, -0.1829],\n",
      "        [-0.2345,  0.2964,  0.2008,  0.1536, -0.3596],\n",
      "        [-0.0363,  0.0244, -0.0666, -0.2013,  0.3473],\n",
      "        [ 0.0407,  0.0947, -0.2300, -0.1252,  0.2743],\n",
      "        [-0.2055, -0.0200, -0.3946, -0.1247,  0.2620],\n",
      "        [-0.2680, -0.2256, -0.1557,  0.3557,  0.0820]], requires_grad=True))\n",
      "('l.bias', Parameter containing:\n",
      "tensor([-0.0174, -0.0418, -0.3103,  0.3874,  0.3733, -0.0120,  0.3958, -0.0426,\n",
      "        -0.2509, -0.1188], requires_grad=True))\n",
      "('l1.weight', Parameter containing:\n",
      "tensor([[ 0.0634,  0.2221, -0.1416,  0.1017, -0.1207,  0.0477, -0.2734, -0.1802,\n",
      "          0.2154, -0.0621]], requires_grad=True))\n",
      "('l1.bias', Parameter containing:\n",
      "tensor([-0.1163], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i.weight and Parameter containing:\n",
      "tensor([[-0.0197,  0.4276],\n",
      "        [-0.3853, -0.0511],\n",
      "        [-0.4546,  0.3857],\n",
      "        [-0.0220, -0.6716],\n",
      "        [ 0.3855,  0.2678]], requires_grad=True) \n",
      "\n",
      "\n",
      "i.bias and Parameter containing:\n",
      "tensor([-0.4125,  0.4195, -0.5047,  0.2852, -0.6187], requires_grad=True) \n",
      "\n",
      "\n",
      "l.weight and Parameter containing:\n",
      "tensor([[-0.3708,  0.0031, -0.3170,  0.2373, -0.0396],\n",
      "        [ 0.0556,  0.2937,  0.1855, -0.2691,  0.1801],\n",
      "        [ 0.1217,  0.0841,  0.4051, -0.3729,  0.0954],\n",
      "        [ 0.3591, -0.0588, -0.2873,  0.1234, -0.2960],\n",
      "        [-0.3650, -0.1286, -0.2019,  0.1099, -0.1829],\n",
      "        [-0.2345,  0.2964,  0.2008,  0.1536, -0.3596],\n",
      "        [-0.0363,  0.0244, -0.0666, -0.2013,  0.3473],\n",
      "        [ 0.0407,  0.0947, -0.2300, -0.1252,  0.2743],\n",
      "        [-0.2055, -0.0200, -0.3946, -0.1247,  0.2620],\n",
      "        [-0.2680, -0.2256, -0.1557,  0.3557,  0.0820]], requires_grad=True) \n",
      "\n",
      "\n",
      "l.bias and Parameter containing:\n",
      "tensor([-0.0174, -0.0418, -0.3103,  0.3874,  0.3733, -0.0120,  0.3958, -0.0426,\n",
      "        -0.2509, -0.1188], requires_grad=True) \n",
      "\n",
      "\n",
      "l1.weight and Parameter containing:\n",
      "tensor([[ 0.0634,  0.2221, -0.1416,  0.1017, -0.1207,  0.0477, -0.2734, -0.1802,\n",
      "          0.2154, -0.0621]], requires_grad=True) \n",
      "\n",
      "\n",
      "l1.bias and Parameter containing:\n",
      "tensor([-0.1163], requires_grad=True) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i[0],\"and\",i[1],'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.4492]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4492]]) None <SigmoidBackward object at 0x000002D9050E8048>\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(loss.data, loss.grad, loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=5, out_features=10, bias=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0174, -0.0418, -0.3103,  0.3874,  0.3733, -0.0120,  0.3958, -0.0426,\n",
      "        -0.2509, -0.1188], requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> Parameter containing:\n",
      "tensor([-0.0174, -0.0418, -0.3103,  0.3874,  0.3733, -0.0120,  0.3958, -0.0426,\n",
      "        -0.2509, -0.1188], requires_grad=True) tensor([ 0.0157,  0.0550, -0.0350,  0.0252, -0.0299,  0.0118, -0.0676, -0.0446,\n",
      "         0.0533, -0.0154])\n"
     ]
    }
   ],
   "source": [
    "print(model.l)\n",
    "print(model.l.bias)\n",
    "print(type(model.l.bias),model.l.bias,model.l.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.6969e-03,  6.6572e-05, -1.1340e-02, -2.2752e-03, -1.1192e-03],\n",
       "        [-9.4555e-03,  2.3341e-04, -3.9760e-02, -7.9769e-03, -3.9241e-03],\n",
       "        [ 6.0279e-03, -1.4880e-04,  2.5347e-02,  5.0853e-03,  2.5016e-03],\n",
       "        [-4.3288e-03,  1.0686e-04, -1.8203e-02, -3.6519e-03, -1.7965e-03],\n",
       "        [ 5.1392e-03, -1.2686e-04,  2.1610e-02,  4.3355e-03,  2.1328e-03],\n",
       "        [-2.0287e-03,  5.0080e-05, -8.5308e-03, -1.7115e-03, -8.4194e-04],\n",
       "        [ 1.1638e-02, -2.8729e-04,  4.8938e-02,  9.8183e-03,  4.8299e-03],\n",
       "        [ 7.6701e-03, -1.8934e-04,  3.2252e-02,  6.4707e-03,  3.1831e-03],\n",
       "        [-9.1694e-03,  2.2635e-04, -3.8557e-02, -7.7356e-03, -3.8053e-03],\n",
       "        [ 2.6420e-03, -6.5218e-05,  1.1110e-02,  2.2289e-03,  1.0965e-03]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.l.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(),lr=1)  #Uses the grad computed in backward() to update the weights using some optimization and lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() #step actually computes the x_t+1 from x_t, grad and lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.6969e-03,  6.6572e-05, -1.1340e-02, -2.2752e-03, -1.1192e-03],\n",
       "        [-9.4555e-03,  2.3341e-04, -3.9760e-02, -7.9769e-03, -3.9241e-03],\n",
       "        [ 6.0279e-03, -1.4880e-04,  2.5347e-02,  5.0853e-03,  2.5016e-03],\n",
       "        [-4.3288e-03,  1.0686e-04, -1.8203e-02, -3.6519e-03, -1.7965e-03],\n",
       "        [ 5.1392e-03, -1.2686e-04,  2.1610e-02,  4.3355e-03,  2.1328e-03],\n",
       "        [-2.0287e-03,  5.0080e-05, -8.5308e-03, -1.7115e-03, -8.4194e-04],\n",
       "        [ 1.1638e-02, -2.8729e-04,  4.8938e-02,  9.8183e-03,  4.8299e-03],\n",
       "        [ 7.6701e-03, -1.8934e-04,  3.2252e-02,  6.4707e-03,  3.1831e-03],\n",
       "        [-9.1694e-03,  2.2635e-04, -3.8557e-02, -7.7356e-03, -3.8053e-03],\n",
       "        [ 2.6420e-03, -6.5218e-05,  1.1110e-02,  2.2289e-03,  1.0965e-03]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.l.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
       "        [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
       "        [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
       "        [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
       "        [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
       "        [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
       "        [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
       "        [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
       "        [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
       "        [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model.l.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[-0.0236,  0.4252],\n",
       "           [-0.4008, -0.0606],\n",
       "           [-0.4430,  0.3929],\n",
       "           [-0.0327, -0.6781],\n",
       "           [ 0.4088,  0.2820]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.4164,  0.4039, -0.4930,  0.2744, -0.5954], requires_grad=True), Parameter containing:\n",
       "   tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
       "           [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
       "           [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
       "           [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
       "           [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
       "           [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
       "           [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
       "           [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
       "           [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
       "           [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.0331, -0.0968, -0.2753,  0.3622,  0.4031, -0.0238,  0.4634,  0.0020,\n",
       "           -0.3042, -0.1035], requires_grad=True), Parameter containing:\n",
       "   tensor([[ 0.0030,  0.2612,  0.0011, -0.0310, -0.2639,  0.0755, -0.3859, -0.2088,\n",
       "             0.1983, -0.0575]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.3637], requires_grad=True)],\n",
       "  'lr': 1,\n",
       "  'momentum': 0,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False}]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "optimizer.param_groups  #param_groups is a list of dict. Each dict element of the list contains the hyperparameters used to update the weights in the next round. It is a list because a model can have more than one set of optimizers for diff circumstances (read more about this idk). Accessed by optimizer.param_groups[0]['lr'] or optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NeuralNet' object has no attribute 'param_groups'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2191fb5ada21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    583\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 585\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNet' object has no attribute 'param_groups'"
     ]
    }
   ],
   "source": [
    "model.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0236,  0.4252],\n",
       "         [-0.4008, -0.0606],\n",
       "         [-0.4430,  0.3929],\n",
       "         [-0.0327, -0.6781],\n",
       "         [ 0.4088,  0.2820]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.4164,  0.4039, -0.4930,  0.2744, -0.5954], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
       "         [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
       "         [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
       "         [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
       "         [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
       "         [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
       "         [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
       "         [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
       "         [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
       "         [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.0331, -0.0968, -0.2753,  0.3622,  0.4031, -0.0238,  0.4634,  0.0020,\n",
       "         -0.3042, -0.1035], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0030,  0.2612,  0.0011, -0.0310, -0.2639,  0.0755, -0.3859, -0.2088,\n",
       "           0.1983, -0.0575]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.3637], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0236,  0.4252],\n",
      "        [-0.4008, -0.0606],\n",
      "        [-0.4430,  0.3929],\n",
      "        [-0.0327, -0.6781],\n",
      "        [ 0.4088,  0.2820]], requires_grad=True)\n",
      "s\n",
      "Parameter containing:\n",
      "tensor([-0.4164,  0.4039, -0.4930,  0.2744, -0.5954], requires_grad=True)\n",
      "s\n",
      "Parameter containing:\n",
      "tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
      "        [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
      "        [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
      "        [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
      "        [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
      "        [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
      "        [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
      "        [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
      "        [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
      "        [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]], requires_grad=True)\n",
      "s\n",
      "Parameter containing:\n",
      "tensor([-0.0331, -0.0968, -0.2753,  0.3622,  0.4031, -0.0238,  0.4634,  0.0020,\n",
      "        -0.3042, -0.1035], requires_grad=True)\n",
      "s\n",
      "Parameter containing:\n",
      "tensor([[ 0.0030,  0.2612,  0.0011, -0.0310, -0.2639,  0.0755, -0.3859, -0.2088,\n",
      "          0.1983, -0.0575]], requires_grad=True)\n",
      "s\n",
      "Parameter containing:\n",
      "tensor([-0.3637], requires_grad=True)\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "for group in optimizer.param_groups:\n",
    "    #print(group['lr'])\n",
    "    for i, p in enumerate(group['params']):\n",
    "        y=torch.ones(p.data.shape)\n",
    "        #p.data.add_(1,y)\n",
    "        print(p)\n",
    "        print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[-0.0236,  0.4252],\n",
      "        [-0.4008, -0.0606],\n",
      "        [-0.4430,  0.3929],\n",
      "        [-0.0327, -0.6781],\n",
      "        [ 0.4088,  0.2820]]), tensor([-0.4164,  0.4039, -0.4930,  0.2744, -0.5954]), tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
      "        [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
      "        [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
      "        [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
      "        [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
      "        [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
      "        [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
      "        [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
      "        [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
      "        [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]]), tensor([-0.0331, -0.0968, -0.2753,  0.3622,  0.4031, -0.0238,  0.4634,  0.0020,\n",
      "        -0.3042, -0.1035]), tensor([[ 0.0030,  0.2612,  0.0011, -0.0310, -0.2639,  0.0755, -0.3859, -0.2088,\n",
      "          0.1983, -0.0575]]), tensor([-0.3637])]\n"
     ]
    }
   ],
   "source": [
    "tensor_params=[]\n",
    "x=model.parameters()\n",
    "for i,j in enumerate(x):\n",
    "    tensor_params.append(j.data)\n",
    "\n",
    "print(tensor_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('i.weight', tensor([[-0.0236,  0.4252],\n",
       "                      [-0.4008, -0.0606],\n",
       "                      [-0.4430,  0.3929],\n",
       "                      [-0.0327, -0.6781],\n",
       "                      [ 0.4088,  0.2820]])),\n",
       "             ('i.bias', tensor([-0.4164,  0.4039, -0.4930,  0.2744, -0.5954])),\n",
       "             ('l.weight',\n",
       "              tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
       "                      [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
       "                      [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
       "                      [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
       "                      [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
       "                      [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
       "                      [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
       "                      [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
       "                      [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
       "                      [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]])),\n",
       "             ('l.bias',\n",
       "              tensor([-0.0331, -0.0968, -0.2753,  0.3622,  0.4031, -0.0238,  0.4634,  0.0020,\n",
       "                      -0.3042, -0.1035])),\n",
       "             ('l1.weight',\n",
       "              tensor([[ 0.0030,  0.2612,  0.0011, -0.0310, -0.2639,  0.0755, -0.3859, -0.2088,\n",
       "                        0.1983, -0.0575]])),\n",
       "             ('l1.bias', tensor([-0.3637]))])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model's state_dict:\n",
      "i.weight \t torch.Size([5, 2]) \n",
      " the weights are: tensor([[-0.0236,  0.4252],\n",
      "        [-0.4008, -0.0606],\n",
      "        [-0.4430,  0.3929],\n",
      "        [-0.0327, -0.6781],\n",
      "        [ 0.4088,  0.2820]]) \n",
      "\n",
      "i.bias \t torch.Size([5]) \n",
      " the weights are: tensor([-0.4164,  0.4039, -0.4930,  0.2744, -0.5954]) \n",
      "\n",
      "l.weight \t torch.Size([10, 5]) \n",
      " the weights are: tensor([[-0.3681,  0.0030, -0.3057,  0.2396, -0.0384],\n",
      "        [ 0.0650,  0.2935,  0.2253, -0.2612,  0.1840],\n",
      "        [ 0.1157,  0.0843,  0.3798, -0.3780,  0.0929],\n",
      "        [ 0.3634, -0.0589, -0.2691,  0.1271, -0.2942],\n",
      "        [-0.3702, -0.1285, -0.2235,  0.1056, -0.1851],\n",
      "        [-0.2325,  0.2964,  0.2094,  0.1553, -0.3588],\n",
      "        [-0.0479,  0.0247, -0.1155, -0.2111,  0.3425],\n",
      "        [ 0.0330,  0.0949, -0.2623, -0.1317,  0.2711],\n",
      "        [-0.1963, -0.0203, -0.3560, -0.1169,  0.2658],\n",
      "        [-0.2707, -0.2255, -0.1668,  0.3534,  0.0809]]) \n",
      "\n",
      "l.bias \t torch.Size([10]) \n",
      " the weights are: tensor([-0.0331, -0.0968, -0.2753,  0.3622,  0.4031, -0.0238,  0.4634,  0.0020,\n",
      "        -0.3042, -0.1035]) \n",
      "\n",
      "l1.weight \t torch.Size([1, 10]) \n",
      " the weights are: tensor([[ 0.0030,  0.2612,  0.0011, -0.0310, -0.2639,  0.0755, -0.3859, -0.2088,\n",
      "          0.1983, -0.0575]]) \n",
      "\n",
      "l1.bias \t torch.Size([1]) \n",
      " the weights are: tensor([-0.3637]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding model weights to themselves using state_dict\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "sd=model.state_dict()\n",
    "for param_tensor in sd:\n",
    "    print(param_tensor, \"\\t\", sd[param_tensor].size(),\"\\n the weights are:\", sd[param_tensor],\"\\n\")\n",
    "    sd[param_tensor]+=sd[param_tensor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('i.weight', tensor([[-0.0472,  0.8504],\n",
       "                      [-0.8017, -0.1212],\n",
       "                      [-0.8859,  0.7857],\n",
       "                      [-0.0653, -1.3563],\n",
       "                      [ 0.8175,  0.5640]])),\n",
       "             ('i.bias', tensor([-0.8328,  0.8078, -0.9860,  0.5489, -1.1909])),\n",
       "             ('l.weight',\n",
       "              tensor([[-0.7362,  0.0060, -0.6114,  0.4792, -0.0769],\n",
       "                      [ 0.1301,  0.5870,  0.4505, -0.5223,  0.3680],\n",
       "                      [ 0.2314,  0.1685,  0.7595, -0.7560,  0.1859],\n",
       "                      [ 0.7268, -0.1178, -0.5383,  0.2542, -0.5884],\n",
       "                      [-0.7404, -0.2570, -0.4471,  0.2112, -0.3701],\n",
       "                      [-0.4649,  0.5927,  0.4187,  0.3106, -0.7176],\n",
       "                      [-0.0958,  0.0493, -0.2311, -0.4222,  0.6849],\n",
       "                      [ 0.0660,  0.1898, -0.5246, -0.2633,  0.5423],\n",
       "                      [-0.3926, -0.0405, -0.7121, -0.2339,  0.5317],\n",
       "                      [-0.5414, -0.4511, -0.3335,  0.7069,  0.1618]])),\n",
       "             ('l.bias',\n",
       "              tensor([-0.0662, -0.1935, -0.5506,  0.7245,  0.8063, -0.0476,  0.9269,  0.0040,\n",
       "                      -0.6084, -0.2070])),\n",
       "             ('l1.weight',\n",
       "              tensor([[ 0.0059,  0.5225,  0.0022, -0.0621, -0.5278,  0.1509, -0.7718, -0.4177,\n",
       "                        0.3965, -0.1150]])),\n",
       "             ('l1.bias', tensor([-0.7274]))])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 1,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [3133038966176,\n",
       "    3131056412208,\n",
       "    3131056412280,\n",
       "    3131056412352,\n",
       "    3131056412424,\n",
       "    3131056412496]}]}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3133038966176"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "optimizer.state_dict()['param_groups'][0]['params'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[-0.0472,  0.8504],\n",
       "           [-0.8017, -0.1212],\n",
       "           [-0.8859,  0.7857],\n",
       "           [-0.0653, -1.3563],\n",
       "           [ 0.8175,  0.5640]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.8328,  0.8078, -0.9860,  0.5489, -1.1909], requires_grad=True), Parameter containing:\n",
       "   tensor([[-0.7362,  0.0060, -0.6114,  0.4792, -0.0769],\n",
       "           [ 0.1301,  0.5870,  0.4505, -0.5223,  0.3680],\n",
       "           [ 0.2314,  0.1685,  0.7595, -0.7560,  0.1859],\n",
       "           [ 0.7268, -0.1178, -0.5383,  0.2542, -0.5884],\n",
       "           [-0.7404, -0.2570, -0.4471,  0.2112, -0.3701],\n",
       "           [-0.4649,  0.5927,  0.4187,  0.3106, -0.7176],\n",
       "           [-0.0958,  0.0493, -0.2311, -0.4222,  0.6849],\n",
       "           [ 0.0660,  0.1898, -0.5246, -0.2633,  0.5423],\n",
       "           [-0.3926, -0.0405, -0.7121, -0.2339,  0.5317],\n",
       "           [-0.5414, -0.4511, -0.3335,  0.7069,  0.1618]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.0662, -0.1935, -0.5506,  0.7245,  0.8063, -0.0476,  0.9269,  0.0040,\n",
       "           -0.6084, -0.2070], requires_grad=True), Parameter containing:\n",
       "   tensor([[ 0.0059,  0.5225,  0.0022, -0.0621, -0.5278,  0.1509, -0.7718, -0.4177,\n",
       "             0.3965, -0.1150]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.7274], requires_grad=True)],\n",
       "  'lr': 1,\n",
       "  'momentum': 0,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False}]"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "optimizer.param_groups #note this has different parameters from the params in state_dict. Are the values of params in state_dict just pointers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0472,  0.8504],\n",
       "        [-0.8017, -0.1212],\n",
       "        [-0.8859,  0.7857],\n",
       "        [-0.0653, -1.3563],\n",
       "        [ 0.8175,  0.5640]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "#Will weights updated in model reflect in optimizer?\n",
    "\n",
    "optimizer.param_groups[0]['params'][0] #.data gives just the tensor. The tensor data has updated to the new weights set in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0039,  0.0024],\n",
       "        [ 0.0156,  0.0095],\n",
       "        [-0.0116, -0.0071],\n",
       "        [ 0.0107,  0.0065],\n",
       "        [-0.0232, -0.0142]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params'][0].grad.data #there is no grad initially, until forward and back are called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will weights updated in optimizer reflect in model?\n",
    "optimizer.param_groups[0]['params'][0].data+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9528,  1.8504],\n",
       "        [ 0.1983,  0.8788],\n",
       "        [ 0.1141,  1.7857],\n",
       "        [ 0.9347, -0.3563],\n",
       "        [ 1.8175,  1.5640]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('i.weight', tensor([[ 0.9528,  1.8504],\n",
       "                      [ 0.1983,  0.8788],\n",
       "                      [ 0.1141,  1.7857],\n",
       "                      [ 0.9347, -0.3563],\n",
       "                      [ 1.8175,  1.5640]])),\n",
       "             ('i.bias', tensor([-0.8328,  0.8078, -0.9860,  0.5489, -1.1909])),\n",
       "             ('l.weight',\n",
       "              tensor([[-0.7362,  0.0060, -0.6114,  0.4792, -0.0769],\n",
       "                      [ 0.1301,  0.5870,  0.4505, -0.5223,  0.3680],\n",
       "                      [ 0.2314,  0.1685,  0.7595, -0.7560,  0.1859],\n",
       "                      [ 0.7268, -0.1178, -0.5383,  0.2542, -0.5884],\n",
       "                      [-0.7404, -0.2570, -0.4471,  0.2112, -0.3701],\n",
       "                      [-0.4649,  0.5927,  0.4187,  0.3106, -0.7176],\n",
       "                      [-0.0958,  0.0493, -0.2311, -0.4222,  0.6849],\n",
       "                      [ 0.0660,  0.1898, -0.5246, -0.2633,  0.5423],\n",
       "                      [-0.3926, -0.0405, -0.7121, -0.2339,  0.5317],\n",
       "                      [-0.5414, -0.4511, -0.3335,  0.7069,  0.1618]])),\n",
       "             ('l.bias',\n",
       "              tensor([-0.0662, -0.1935, -0.5506,  0.7245,  0.8063, -0.0476,  0.9269,  0.0040,\n",
       "                      -0.6084, -0.2070])),\n",
       "             ('l1.weight',\n",
       "              tensor([[ 0.0059,  0.5225,  0.0022, -0.0621, -0.5278,  0.1509, -0.7718, -0.4177,\n",
       "                        0.3965, -0.1150]])),\n",
       "             ('l1.bias', tensor([-0.7274]))])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "model.state_dict()  #see that the first model weights have updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Named Parameters Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of NeuralNet(\n",
       "  (i): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (l): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (l1): Linear(in_features=10, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x000002D9053989A8>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'i.weight': Parameter containing:\n",
       " tensor([[ 0.9528,  1.8504],\n",
       "         [ 0.1983,  0.8788],\n",
       "         [ 0.1141,  1.7857],\n",
       "         [ 0.9347, -0.3563],\n",
       "         [ 1.8175,  1.5640]], requires_grad=True),\n",
       " 'i.bias': Parameter containing:\n",
       " tensor([-0.8328,  0.8078, -0.9860,  0.5489, -1.1909], requires_grad=True),\n",
       " 'l.weight': Parameter containing:\n",
       " tensor([[-0.7362,  0.0060, -0.6114,  0.4792, -0.0769],\n",
       "         [ 0.1301,  0.5870,  0.4505, -0.5223,  0.3680],\n",
       "         [ 0.2314,  0.1685,  0.7595, -0.7560,  0.1859],\n",
       "         [ 0.7268, -0.1178, -0.5383,  0.2542, -0.5884],\n",
       "         [-0.7404, -0.2570, -0.4471,  0.2112, -0.3701],\n",
       "         [-0.4649,  0.5927,  0.4187,  0.3106, -0.7176],\n",
       "         [-0.0958,  0.0493, -0.2311, -0.4222,  0.6849],\n",
       "         [ 0.0660,  0.1898, -0.5246, -0.2633,  0.5423],\n",
       "         [-0.3926, -0.0405, -0.7121, -0.2339,  0.5317],\n",
       "         [-0.5414, -0.4511, -0.3335,  0.7069,  0.1618]], requires_grad=True),\n",
       " 'l.bias': Parameter containing:\n",
       " tensor([-0.0662, -0.1935, -0.5506,  0.7245,  0.8063, -0.0476,  0.9269,  0.0040,\n",
       "         -0.6084, -0.2070], requires_grad=True),\n",
       " 'l1.weight': Parameter containing:\n",
       " tensor([[ 0.0059,  0.5225,  0.0022, -0.0621, -0.5278,  0.1509, -0.7718, -0.4177,\n",
       "           0.3965, -0.1150]], requires_grad=True),\n",
       " 'l1.bias': Parameter containing:\n",
       " tensor([-0.7274], requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add weights and copy back to model\n",
    "d=dict(model.named_parameters())\n",
    "for name,param in model.named_parameters():\n",
    "    d[name].data.copy_(param+param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'i.weight': Parameter containing:\n",
       " tensor([[ 1.9056,  3.7007],\n",
       "         [ 0.3966,  1.7576],\n",
       "         [ 0.2282,  3.5714],\n",
       "         [ 1.8694, -0.7126],\n",
       "         [ 3.6351,  3.1281]], requires_grad=True),\n",
       " 'i.bias': Parameter containing:\n",
       " tensor([-1.6656,  1.6156, -1.9721,  1.0977, -2.3817], requires_grad=True),\n",
       " 'l.weight': Parameter containing:\n",
       " tensor([[-1.4725,  0.0119, -1.2227,  0.9584, -0.1538],\n",
       "         [ 0.2602,  1.1740,  0.9010, -1.0446,  0.7360],\n",
       "         [ 0.4627,  0.3370,  1.5191, -1.5120,  0.3718],\n",
       "         [ 1.4536, -0.2356, -1.0765,  0.5083, -1.1769],\n",
       "         [-1.4808, -0.5141, -0.8942,  0.4225, -0.7403],\n",
       "         [-0.9298,  1.1854,  0.8375,  0.6212, -1.4352],\n",
       "         [-0.1916,  0.0987, -0.4621, -0.8445,  1.3699],\n",
       "         [ 0.1320,  0.3795, -1.0492, -0.5266,  1.0845],\n",
       "         [-0.7853, -0.0810, -1.4242, -0.4678,  1.0634],\n",
       "         [-1.0827, -0.9021, -0.6671,  1.4137,  0.3235]], requires_grad=True),\n",
       " 'l.bias': Parameter containing:\n",
       " tensor([-0.1324, -0.3871, -1.1012,  1.4490,  1.6125, -0.0953,  1.8538,  0.0080,\n",
       "         -1.2167, -0.4140], requires_grad=True),\n",
       " 'l1.weight': Parameter containing:\n",
       " tensor([[ 0.0118,  1.0450,  0.0043, -0.1242, -1.0556,  0.3018, -1.5436, -0.8354,\n",
       "           0.7931, -0.2299]], requires_grad=True),\n",
       " 'l1.bias': Parameter containing:\n",
       " tensor([-1.4547], requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "#Now load the dictionary as a state\n",
    "model.load_state_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'i.weight': Parameter containing:\n",
       " tensor([[ 1.9056,  3.7007],\n",
       "         [ 0.3966,  1.7576],\n",
       "         [ 0.2282,  3.5714],\n",
       "         [ 1.8694, -0.7126],\n",
       "         [ 3.6351,  3.1281]], requires_grad=True),\n",
       " 'i.bias': Parameter containing:\n",
       " tensor([-1.6656,  1.6156, -1.9721,  1.0977, -2.3817], requires_grad=True),\n",
       " 'l.weight': Parameter containing:\n",
       " tensor([[-1.4725,  0.0119, -1.2227,  0.9584, -0.1538],\n",
       "         [ 0.2602,  1.1740,  0.9010, -1.0446,  0.7360],\n",
       "         [ 0.4627,  0.3370,  1.5191, -1.5120,  0.3718],\n",
       "         [ 1.4536, -0.2356, -1.0765,  0.5083, -1.1769],\n",
       "         [-1.4808, -0.5141, -0.8942,  0.4225, -0.7403],\n",
       "         [-0.9298,  1.1854,  0.8375,  0.6212, -1.4352],\n",
       "         [-0.1916,  0.0987, -0.4621, -0.8445,  1.3699],\n",
       "         [ 0.1320,  0.3795, -1.0492, -0.5266,  1.0845],\n",
       "         [-0.7853, -0.0810, -1.4242, -0.4678,  1.0634],\n",
       "         [-1.0827, -0.9021, -0.6671,  1.4137,  0.3235]], requires_grad=True),\n",
       " 'l.bias': Parameter containing:\n",
       " tensor([-0.1324, -0.3871, -1.1012,  1.4490,  1.6125, -0.0953,  1.8538,  0.0080,\n",
       "         -1.2167, -0.4140], requires_grad=True),\n",
       " 'l1.weight': Parameter containing:\n",
       " tensor([[ 0.0118,  1.0450,  0.0043, -0.1242, -1.0556,  0.3018, -1.5436, -0.8354,\n",
       "           0.7931, -0.2299]], requires_grad=True),\n",
       " 'l1.bias': Parameter containing:\n",
       " tensor([-1.4547], requires_grad=True)}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 1.9056,  3.7007],\n",
       "           [ 0.3966,  1.7576],\n",
       "           [ 0.2282,  3.5714],\n",
       "           [ 1.8694, -0.7126],\n",
       "           [ 3.6351,  3.1281]], requires_grad=True), Parameter containing:\n",
       "   tensor([-1.6656,  1.6156, -1.9721,  1.0977, -2.3817], requires_grad=True), Parameter containing:\n",
       "   tensor([[-1.4725,  0.0119, -1.2227,  0.9584, -0.1538],\n",
       "           [ 0.2602,  1.1740,  0.9010, -1.0446,  0.7360],\n",
       "           [ 0.4627,  0.3370,  1.5191, -1.5120,  0.3718],\n",
       "           [ 1.4536, -0.2356, -1.0765,  0.5083, -1.1769],\n",
       "           [-1.4808, -0.5141, -0.8942,  0.4225, -0.7403],\n",
       "           [-0.9298,  1.1854,  0.8375,  0.6212, -1.4352],\n",
       "           [-0.1916,  0.0987, -0.4621, -0.8445,  1.3699],\n",
       "           [ 0.1320,  0.3795, -1.0492, -0.5266,  1.0845],\n",
       "           [-0.7853, -0.0810, -1.4242, -0.4678,  1.0634],\n",
       "           [-1.0827, -0.9021, -0.6671,  1.4137,  0.3235]], requires_grad=True), Parameter containing:\n",
       "   tensor([-0.1324, -0.3871, -1.1012,  1.4490,  1.6125, -0.0953,  1.8538,  0.0080,\n",
       "           -1.2167, -0.4140], requires_grad=True), Parameter containing:\n",
       "   tensor([[ 0.0118,  1.0450,  0.0043, -0.1242, -1.0556,  0.3018, -1.5436, -0.8354,\n",
       "             0.7931, -0.2299]], requires_grad=True), Parameter containing:\n",
       "   tensor([-1.4547], requires_grad=True)],\n",
       "  'lr': 1,\n",
       "  'momentum': 0,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False}]"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_idxs= partition[76]\n",
    "\n",
    "train_data=np.random.choice(datapoint_idxs,64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in train_data:\n",
    "    x_train.append(list(traindata[i][0]))\n",
    "    y_train.append(float(traindata[i][1][0]))\n",
    "    \n",
    "x_train=torch.tensor(x_train)\n",
    "y_train=torch.tensor(y_train)\n",
    "\n",
    "ta = data_utils.TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "single_minibatch_loader = data_utils.DataLoader(ta, shuffle=False,batch_size= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in single_minibatch_loader:\n",
    "    print(data[0].size()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(optimi.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([1,2,3,4])\n",
    "y=torch.tensor([5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.add_(-1,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of NeuralNet(\n",
       "  (i): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (l): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (l1): Linear(in_features=10, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "interpreter": {
   "hash": "cc266ed2f5d57d602e641bd2ce436bffd8b04c77b20088649f4b506953061e74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}