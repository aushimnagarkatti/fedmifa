import lenet
import numpy as np

#Generic Hyp
batch_size= 64 #Neural Network batch size
n_rnds= 1500 #Global rounds
tau=5 #Local rounds --> not in use since we use local epochs
total_c= 250 #250 #Total no of clients
no_of_c=[5] #participating clients
local_epochs = 5 
plot_local_train_loss = True


#Cluster
K= 36 #55        #try for 5,10,20. Number of clusters is predetermined for static
cluster = 1
clust_mech = 'static' #'static 

#Model
model_type = 'lenet' #shakespeare_lstm' #'shakespeare_lstm'#'cnnmnist'#'cnnmnist' #'r'
dataset = 'cifar10'

#Plotting
plot_every_n = 20



#Learning rate
algo_lr = {  #lr for each algo, length has to be the same for all algos
    0: [0.05],
    1: [0.05],
    2: [0.05], #0.05
    3: [0.05],
    4: [0.05]
    }

lrfactor = {
    0:1, #factor to reduce lr in scheduler
    1:1,
    2:1,
    3:1,
    4:1
    }

sch_freq = 100 #scheduler every n rounds



#select algos to run
d_algo = {
            0: "MIFA",
            1: "UMIFA",
            2: "FedAvg",
            3: "scaffold",
            4: "UMIFA static"
        }




#MIFA paper paradigm variables
#p_i min is for the paper's paradigm for client selection, each client is selected with a min prob of 0.2
pi_min = 0.2
sel_client_variablepi = False #variable no of clients selected each round according to pi assigned
enforce_cp_r1 = False #enforce all client part in 1st round


loss_algo = [[1.8832127702236179, 0.840946051739125, 0.9276031193137169, 0.8109068682417273, 0.8193751560151578, 0.908358288705349, 0.4972746150378953, 0.38274129867961165, 0.7910000517964362, 0.580015331208706, 0.43903016751632096, 0.5286509211221709, 0.5643646785616875, 0.4777971834316849, 0.5479314173571765, 0.38407625853084026, 0.5319189081341028, 0.2980379146244377, 0.4174709415563848, 0.4235968773707282, 0.36940868137404326, 0.31046655545011165, 0.2646224264265038, 0.21388378407988054, 0.3876926461653784, 0.33621514221362303, 0.2715735246188706, 0.2826846659179864, 0.32625487154815347, 0.24656283092042938, 0.33075390219688416, 0.2216434388863854, 0.3555274303257465, 0.2905760884529445, 0.21317693617093028, 0.21060715967905708, 0.3177710794393352, 0.17116745571399408, 0.23534874372184275, 0.23323543983194212, 0.20545330992521485, 0.19450964736694004, 0.17455761861987412, 0.1450413845735602, 0.14435980623180514, 0.12199559670174494, 0.1683618571131956, 0.2548191978569957, 0.15588003548808044, 0.1799368809349835, 0.16429071078367996, 0.1865528536934471, 0.2729541457418418, 0.14921158544020727, 0.16016684773931048, 0.13871116324327887, 0.19144886219059115, 0.0951517372572789, 0.08024327314924448, 0.08208518849263782, 0.22984490254286358, 0.11389970789583459, 0.09417854795407862, 0.1421980141638778, 0.15069825916783883, 0.1664020309213083, 0.15367995093343778, 0.1251186138371122, 0.09441386307363245, 0.09284110995082302, 0.20924755796091632, 0.12469259180768859, 0.12567417197918984, 0.11872062440495938, 0.15431707396171987], [1.888524835705757, 0.6848854722862598, 0.8050417365133763, 0.5974165320023894, 0.6565312412381172, 0.7177699337899683, 0.41046194565547917, 0.243318163362419, 0.6887886558473111, 0.4375538349559065, 0.3763893514126539, 0.5019932491704822, 0.45168832562863825, 0.3730589160695672, 0.41094897965900606, 0.2717836364288814, 0.4089411417255178, 0.26899142132373527, 0.3895693530107383, 0.3527496083339793, 0.29596654409077017, 0.20341860877815635, 0.15704620137345046, 0.16675735623270155, 0.33374293091474094, 0.3231254353001714, 0.21357945837575248, 0.22282815391896288, 0.20454397531575524, 0.21812688528945726, 0.2148368234746158, 0.21039691408514044, 0.358765722354874, 0.24553282840177415, 0.1342833415440873, 0.1537706562835956, 0.22586238882940962, 0.22436485594708305, 0.16072989170206708, 0.2073693476723565, 0.17047936256116375, 0.2463603528833846, 0.1641509453847539, 0.10644770185230298, 0.12505210055656787, 0.079584797515854, 0.09873780296416954, 0.1523058836178825, 0.22819706096148815, 0.2126155004277825, 0.20833740186613797, 0.09605993532921274, 0.13853718400221623, 0.1870870876481058, 0.08522026308346539, 0.13706434619380162, 0.11062341461190954, 0.09583080770285504, 0.1202537239427329, 0.07996578420104923, 0.23151450863594164, 0.08121126207989164, 0.10019543414644431, 0.10316100824391469, 0.12476859670307021, 0.16671533675660613, 0.08387024497627864, 0.07520930631582246, 0.13991842989425093, 0.08692388136332738, 0.08457320436398733, 0.07538524175237399, 0.18014717301761268, 0.1362609356979374, 0.15990799171151596], [1.8849254781007765, 0.7032476277765818, 0.7514708659052849, 0.5820670107379555, 0.7041747265681625, 0.7344015529751777, 0.4185275137744611, 0.2745804279623553, 0.6056544730067254, 0.4596929393615573, 0.3645141313783825, 0.4632245062291623, 0.4357239663042128, 0.40323776543140405, 0.39852471512276677, 0.35227270724950355, 0.36413459451403474, 0.24202987129800024, 0.36100391358835626, 0.316646465776721, 0.30422540049185043, 0.24976449650945143, 0.17794532172847538, 0.20392954704060684, 0.28618752085138116, 0.2908077391143888, 0.28486626275494925, 0.25595477553597445, 0.2595171414420474, 0.24549139306272988, 0.23122653768863527, 0.16240502664586529, 0.25019395512994375, 0.17874525753781198, 0.1926903903404309, 0.18368608732926078, 0.19422105035599085, 0.11870886836113641, 0.1615130517468788, 0.11868691368988948, 0.12607434787365493, 0.2428651009064197, 0.15730849373969252, 0.18430002786219118, 0.13163462487413197, 0.12778071407781683, 0.14158122075954452, 0.17435816454410086, 0.13319106271751907, 0.2507689737249166, 0.13679588097817033, 0.12631597603271075, 0.17874679727538023, 0.13010531108127904, 0.12743373483535833, 0.13607241170830092, 0.09757411756087095, 0.10193250408796302, 0.07431094012223184, 0.09938015103572981, 0.0931871639608289, 0.18698951529470037, 0.12438776950730243, 0.09801394418347627, 0.09573154719313606, 0.17899513775715606, 0.08624045825679787, 0.08326254035660895, 0.06444218896287565, 0.09101795935363043, 0.07713328090263531, 0.09276148091506911, 0.1402917548379628, 0.08017279269639403, 0.1024417606071802], [1.886868155002594, 0.7152369093813468, 0.8196201027929784, 0.7046257395297288, 0.8260430306196213, 0.8781417603790761, 0.5333176408580039, 0.39689056637696923, 0.8479046423733234, 0.6021974615007639, 0.5228378745540977, 0.6220719127357006, 0.7298007892817259, 0.5619786779209972, 0.6259061830490827, 0.49240922488272193, 0.7170579091459512, 0.4987390934163704, 0.5481568365637213, 0.557549970713444, 0.5090494523383676, 0.4241801656782627, 0.4920338248834014, 0.279635362457484, 0.5657970882579685, 0.6283174296468497, 0.43078665314766107, 0.44026895012706524, 0.4643322102166712, 0.358032330898568, 0.48035629376769073, 0.3593893048539758, 0.5655392394959927, 0.6304924201220274, 0.33697993676178156, 0.4767181105073542, 0.511863448395161, 0.2748825891816523, 0.41133015982806687, 0.4538818298466504, 0.3216844456270337, 0.33592073029838504, 0.3987334057874977, 0.38430672364309426, 0.3460884479572997, 0.30657228430733086, 0.3919904303364456, 0.47583117013331505, 0.4611618861546595, 0.4229956727661192, 0.395597654011799, 0.36457816455280406, 0.468899834472686, 0.5329798378050328, 0.36929913280531756, 0.4913996294327081, 0.44337094161659485, 0.2797722430713475, 0.2648832276277243, 0.2598424507252639, 0.3142271765042096, 0.31595965475164123, 0.3599420610349625, 0.446149243041873, 0.3330039043538272, 0.46518865051679315, 0.3632025646162219, 0.20456941566662862, 0.4464616482902784, 0.2421549542678986, 0.4049113827804104, 0.31513498410582547, 0.41384693227708336, 0.3702115670777858, 0.34420415846630925], [1.8833178812265394, 0.6098019522021059, 0.7884778038412332, 0.5645832073688507, 0.7076267459988594, 0.8725295895338057, 0.35057934601136365, 0.2776972604327602, 0.6697501502931118, 0.4875380299426616, 0.3932994560524821, 0.4509771163598634, 0.531729275798425, 0.4144373082555831, 0.3818691651895642, 0.31627557417377833, 0.41828106590546665, 0.24026263888459648, 0.3356491624331102, 0.31972008172422645, 0.3148370531597175, 0.30545092015061526, 0.22261794092773926, 0.1859604280790518, 0.3711679254518822, 0.30512394529767334, 0.25636104863815484, 0.2808451308028089, 0.2971932011190802, 0.24123089824337512, 0.26829222252767065, 0.1607603988610208, 0.36939462580718097, 0.20418888788204642, 0.1701457956534432, 0.2225351423071697, 0.25009340353368315, 0.1534653598062141, 0.18000234288803768, 0.15774780328090857, 0.14454338650975843, 0.2618742194601146, 0.16728571343177465, 0.15888094226247632, 0.14826834120565763, 0.1150751522911014, 0.31397994420491154, 0.1637674853090721, 0.17230806609499266, 0.2158699672948569, 0.1665248720867021, 0.1468539578968921, 0.1416499962071248, 0.1360865748062497, 0.10357535657472909, 0.12386535047204235, 0.10708943187957631, 0.08340713622294971, 0.11611465834081174, 0.1046140988965999, 0.14710858373233351, 0.1609420414543274, 0.0974678974537619, 0.10288887061644347, 0.0932050481857732, 0.16661624862346797, 0.11424896931392141, 0.07901991585153154, 0.08433087845070986, 0.09032625862404528, 0.09473245075816522, 0.11402967651258225, 0.14081248609232716, 0.14284941435063958, 0.15454964536707846]]
acc_algo = [[tensor(0.0916), tensor(0.1113), tensor(0.1005), tensor(0.2080), tensor(0.2235), tensor(0.2793), tensor(0.3123), tensor(0.3026), tensor(0.3420), tensor(0.3675), tensor(0.3952), tensor(0.4217), tensor(0.4333), tensor(0.4465), tensor(0.4552), tensor(0.4558), tensor(0.4595), tensor(0.4725), tensor(0.4773), tensor(0.4827), tensor(0.4914), tensor(0.4896), tensor(0.4899), tensor(0.4968), tensor(0.4974), tensor(0.4988), tensor(0.4979), tensor(0.5068), tensor(0.5086), tensor(0.5026), tensor(0.5165), tensor(0.5130), tensor(0.5103), tensor(0.5206), tensor(0.5243), tensor(0.5097), tensor(0.5221), tensor(0.5156), tensor(0.5179), tensor(0.5191), tensor(0.5208), tensor(0.5245), tensor(0.5184), tensor(0.5282), tensor(0.5293), tensor(0.5214), tensor(0.5249), tensor(0.5232), tensor(0.5186), tensor(0.5264), tensor(0.5357), tensor(0.5223), tensor(0.5216), tensor(0.5261), tensor(0.5308), tensor(0.5343), tensor(0.5281), tensor(0.5208), tensor(0.5203), tensor(0.5316), tensor(0.5321), tensor(0.5280), tensor(0.5289), tensor(0.5346), tensor(0.5305), tensor(0.5285), tensor(0.5335), tensor(0.5333), tensor(0.5273), tensor(0.5288), tensor(0.5314), tensor(0.5291), tensor(0.5304), tensor(0.5273), tensor(0.5294)], [tensor(0.0916), tensor(0.1655), tensor(0.1941), tensor(0.3155), tensor(0.3094), tensor(0.3996), tensor(0.4407), tensor(0.4405), tensor(0.4170), tensor(0.4784), tensor(0.4910), tensor(0.4814), tensor(0.4964), tensor(0.4968), tensor(0.5123), tensor(0.5081), tensor(0.5143), tensor(0.5200), tensor(0.5215), tensor(0.5282), tensor(0.5255), tensor(0.5256), tensor(0.5361), tensor(0.5337), tensor(0.5332), tensor(0.5157), tensor(0.5128), tensor(0.5393), tensor(0.5333), tensor(0.5372), tensor(0.5216), tensor(0.5304), tensor(0.5381), tensor(0.5354), tensor(0.5375), tensor(0.5345), tensor(0.5294), tensor(0.5231), tensor(0.5341), tensor(0.5396), tensor(0.5401), tensor(0.5392), tensor(0.5409), tensor(0.5376), tensor(0.5437), tensor(0.5446), tensor(0.5473), tensor(0.5330), tensor(0.5352), tensor(0.5344), tensor(0.5384), tensor(0.5515), tensor(0.5568), tensor(0.5468), tensor(0.5375), tensor(0.5396), tensor(0.5481), tensor(0.5448), tensor(0.5422), tensor(0.5399), tensor(0.5321), tensor(0.5372), tensor(0.5413), tensor(0.5414), tensor(0.5460), tensor(0.5401), tensor(0.5474), tensor(0.5418), tensor(0.5398), tensor(0.5484), tensor(0.5466), tensor(0.5452), tensor(0.5393), tensor(0.5465), tensor(0.5434)], [tensor(0.0916), tensor(0.1237), tensor(0.2330), tensor(0.2762), tensor(0.3796), tensor(0.3151), tensor(0.2359), tensor(0.3281), tensor(0.3920), tensor(0.3991), tensor(0.3710), tensor(0.4343), tensor(0.4342), tensor(0.4015), tensor(0.4504), tensor(0.4531), tensor(0.4428), tensor(0.4015), tensor(0.4112), tensor(0.4151), tensor(0.4622), tensor(0.4792), tensor(0.4604), tensor(0.3724), tensor(0.4715), tensor(0.4915), tensor(0.4599), tensor(0.5067), tensor(0.4901), tensor(0.4788), tensor(0.5146), tensor(0.4461), tensor(0.5037), tensor(0.4453), tensor(0.4720), tensor(0.5229), tensor(0.4656), tensor(0.4466), tensor(0.4839), tensor(0.5130), tensor(0.4775), tensor(0.4553), tensor(0.4720), tensor(0.5280), tensor(0.4925), tensor(0.5109), tensor(0.5177), tensor(0.5135), tensor(0.5004), tensor(0.4907), tensor(0.5105), tensor(0.4997), tensor(0.5190), tensor(0.5239), tensor(0.4860), tensor(0.4462), tensor(0.4992), tensor(0.5027), tensor(0.5232), tensor(0.5450), tensor(0.4796), tensor(0.5388), tensor(0.5310), tensor(0.3734), tensor(0.5464), tensor(0.5114), tensor(0.5346), tensor(0.5273), tensor(0.4748), tensor(0.5143), tensor(0.4961), tensor(0.5144), tensor(0.4330), tensor(0.5250), tensor(0.5248)], [tensor(0.0916), tensor(0.1477), tensor(0.2029), tensor(0.2961), tensor(0.3372), tensor(0.3304), tensor(0.3095), tensor(0.3922), tensor(0.3866), tensor(0.4058), tensor(0.3854), tensor(0.4113), tensor(0.4233), tensor(0.4482), tensor(0.4325), tensor(0.4599), tensor(0.4576), tensor(0.3761), tensor(0.4027), tensor(0.4547), tensor(0.4371), tensor(0.4746), tensor(0.4591), tensor(0.3641), tensor(0.4538), tensor(0.4808), tensor(0.4366), tensor(0.4563), tensor(0.4676), tensor(0.4779), tensor(0.4831), tensor(0.4262), tensor(0.4884), tensor(0.4302), tensor(0.4190), tensor(0.4778), tensor(0.4644), tensor(0.4281), tensor(0.4521), tensor(0.4826), tensor(0.4809), tensor(0.4918), tensor(0.4536), tensor(0.5270), tensor(0.4590), tensor(0.4923), tensor(0.4774), tensor(0.4811), tensor(0.4549), tensor(0.4696), tensor(0.4635), tensor(0.4893), tensor(0.4992), tensor(0.5074), tensor(0.4576), tensor(0.4711), tensor(0.5155), tensor(0.4803), tensor(0.4837), tensor(0.5047), tensor(0.4489), tensor(0.4791), tensor(0.5342), tensor(0.4243), tensor(0.5456), tensor(0.4843), tensor(0.4759), tensor(0.4803), tensor(0.4731), tensor(0.5056), tensor(0.5138), tensor(0.4792), tensor(0.4067), tensor(0.5232), tensor(0.5168)], [tensor(0.0916), tensor(0.2116), tensor(0.3075), tensor(0.3523), tensor(0.3980), tensor(0.4127), tensor(0.4074), tensor(0.4532), tensor(0.4566), tensor(0.4628), tensor(0.4654), tensor(0.4545), tensor(0.4773), tensor(0.4746), tensor(0.4891), tensor(0.5034), tensor(0.4915), tensor(0.5126), tensor(0.4982), tensor(0.5104), tensor(0.5066), tensor(0.4967), tensor(0.5161), tensor(0.5238), tensor(0.5178), tensor(0.5182), tensor(0.5207), tensor(0.5193), tensor(0.5100), tensor(0.5161), tensor(0.5216), tensor(0.5224), tensor(0.5248), tensor(0.5249), tensor(0.5137), tensor(0.5237), tensor(0.5351), tensor(0.5357), tensor(0.5299), tensor(0.5396), tensor(0.5362), tensor(0.5328), tensor(0.5236), tensor(0.5344), tensor(0.5347), tensor(0.5362), tensor(0.5263), tensor(0.5312), tensor(0.5209), tensor(0.5416), tensor(0.5358), tensor(0.5309), tensor(0.5304), tensor(0.5347), tensor(0.5355), tensor(0.5382), tensor(0.5328), tensor(0.5252), tensor(0.5403), tensor(0.5336), tensor(0.5360), tensor(0.5368), tensor(0.5465), tensor(0.5412), tensor(0.5397), tensor(0.5401), tensor(0.5474), tensor(0.5534), tensor(0.5373), tensor(0.5363), tensor(0.5501), tensor(0.5375), tensor(0.5334), tensor(0.5514), tensor(0.5474)]]
test_loss_algo= [[2.3058489599045675, 2.5918991292358204, 2.2940573479719224, 2.232237326111763, 2.0820898880624465, 1.9897440785815002, 1.8762870844762036, 1.8787362712204076, 1.806337922242037, 1.6942892719985574, 1.6504921799252747, 1.604066103127352, 1.5652710973836814, 1.5404094062793028, 1.5126111499822823, 1.5147715829739905, 1.5026200083410663, 1.4755906754997885, 1.4659926511679486, 1.456642502432416, 1.4518399800464605, 1.4508330844769812, 1.4460701950036796, 1.4322650880570624, 1.4325403278800333, 1.4385440433101289, 1.432445286945173, 1.4297523122684213, 1.4338921923546275, 1.4510615821097308, 1.4501852472876287, 1.4391750492108095, 1.4423891438800058, 1.4635460703236283, 1.4712465124525083, 1.457012437711096, 1.5113462923438685, 1.4934033736301835, 1.4762983253807018, 1.495259310789169, 1.492961744973614, 1.4695452706069703, 1.5007494744981171, 1.5160128128756383, 1.5018050746553262, 1.499366688500544, 1.5294735929009262, 1.5587565075060366, 1.5330139876930577, 1.5628933310508728, 1.5314592024323288, 1.550228476524353, 1.5706899371116785, 1.557335025185992, 1.5840566093754616, 1.5366079818670917, 1.5435599175987729, 1.5825423913396848, 1.5630701787912162, 1.5623002249723787, 1.6121566029870587, 1.5798934971451, 1.6175926468174928, 1.6027626664775192, 1.5723679627582525, 1.5799108458932039, 1.5833176465550804, 1.5825096406754415, 1.6466771500885107, 1.605154971787884, 1.609560304006953, 1.7171393055824717, 1.6578459845986335, 1.654110090368113, 1.6418057201774257], [2.3058489599045675, 2.2292127062560647, 2.1821781723362625, 2.011456241273576, 1.8379309777241604, 1.6227362125542513, 1.5645949635536047, 1.5332287398113567, 1.5820543310444826, 1.4357504578912335, 1.4188648150984648, 1.4578043564110046, 1.412656893396074, 1.4005208448239952, 1.3845213887038503, 1.4106428573845298, 1.3831140471112198, 1.3762235948993902, 1.3981310622707295, 1.365821801173459, 1.385316572371562, 1.3731807732278374, 1.3493308007337486, 1.3958924431709727, 1.3650522885049226, 1.4364919875078141, 1.4540892725537538, 1.3885915321149644, 1.380581063070115, 1.3902743511898503, 1.4685153759968508, 1.427374119591561, 1.404690657451654, 1.4024780145875968, 1.4497778066404305, 1.4884938719166312, 1.5127066882552616, 1.4857887940801633, 1.4908561566073424, 1.4434064247046308, 1.4477969438407072, 1.4737760246179665, 1.518149260502712, 1.510562424067479, 1.4877510488412942, 1.492746749121672, 1.555436248612252, 1.5300767171155116, 1.5310048836811332, 1.477293713077618, 1.5055541324008042, 1.5011698030362464, 1.5519017823942147, 1.483216683196414, 1.5082859264057913, 1.5129868866531713, 1.5077349125959312, 1.4962421283600436, 1.5311586872027938, 1.6106571672828334, 1.5658741274457069, 1.6202053803547172, 1.540416857998842, 1.5857128888178782, 1.5165353592034359, 1.6664291198845882, 1.6762346257070067, 1.6295255900947911, 1.5585449026648406, 1.5735979239652111, 1.593778426100494, 1.6359911302852024, 1.6436240521206218, 1.6377020261849566, 1.5613554681941961], [2.3058489599045675, 2.4652652451946477, 2.178292112745297, 2.04989965933903, 1.698001634543109, 1.9538665220236322, 2.4002157662324843, 2.1981090550210065, 1.771905887658429, 1.6879112333249136, 2.0388322825644427, 1.6451971667587377, 1.6322097451823532, 1.7457765796381957, 1.6359732280111616, 1.6017574033919413, 1.6206128103717876, 1.8126691534261035, 1.7841611637431345, 1.8824777390546859, 1.7947946604649732, 1.7075132078425899, 1.6543823298375318, 2.283031084734923, 1.6402408302209939, 1.6068665267555577, 1.647864179626392, 1.517827122834078, 1.6709225200543738, 1.61173223082427, 1.4894206987065115, 2.0951883625832335, 1.5804725513336764, 1.9256094770067056, 1.7816068830004164, 1.5358607655118226, 1.7452916985104798, 1.9341812688074294, 1.8215431627953889, 1.6928110251760786, 1.7809459973292745, 1.903117987760313, 1.9378951203291583, 1.5546186892849625, 1.8121938781373819, 1.7090716301255924, 1.6851027771166176, 1.6032665109938118, 1.8298810348389254, 1.7848276727518457, 1.7012442562990129, 1.7935536910014547, 1.6011395872018899, 1.753164319475745, 1.8532491580695862, 2.0591735581683506, 1.9122479865505437, 1.6748939175514659, 1.7893143505047842, 1.5755145462455264, 1.9167117191727754, 1.5682283643704311, 1.6637477290098834, 3.1149701373592302, 1.5883594679225022, 1.7192440458164093, 1.7640058736132969, 1.7528524391210762, 2.087301203399707, 1.6769244799948042, 1.9319935824461043, 1.8443404026092238, 2.350730160239396, 1.8171953209646188, 1.7852665223893087], [2.3058489599045675, 2.344899141105117, 2.275320836692859, 2.006910284613348, 1.78010405704474, 1.898394667418899, 1.832718394364521, 1.7102655688668513, 1.7034780652659713, 1.618072223511471, 1.8349318094314284, 1.7946571058528438, 1.6758463246047877, 1.5530966326689264, 1.6325635811325852, 1.5125968494233053, 1.5038796556983025, 1.7389684384036217, 1.721659213114696, 1.6283311456631704, 1.7468863793998768, 1.5455581564812144, 1.5133310510854052, 1.9481999114820152, 1.5752309325394358, 1.5038422771320221, 1.6825445222247177, 1.6218105919042212, 1.6267985189036958, 1.6175971638624835, 1.6576745942899376, 1.8592004320424074, 1.5233603396992774, 1.6661185443780984, 1.9443218867490246, 1.619094612492118, 1.5338786043179262, 1.7150456867400248, 1.6985225920464582, 1.5070115229126755, 1.6042297630553033, 1.5244778971763173, 1.6803883382469227, 1.3989030733989303, 1.6065124455530932, 1.6321409272540146, 1.6056146257242578, 1.5149234472566349, 1.7245070926702706, 1.727648616596392, 1.5650447481756757, 1.566972485773123, 1.4690610671498974, 1.5035068950835306, 1.735885339557745, 1.5889940269433769, 1.4633626186164321, 1.5103557527444924, 1.6688766775617174, 1.4797072524477721, 1.8243593994978886, 1.7499513960188362, 1.411604098073996, 1.8303681976476294, 1.3656466728562762, 1.7001593864647446, 1.804054870726956, 1.7967298053632117, 1.7914632786611082, 1.579800951253077, 1.4830802139962556, 1.7791726384193274, 2.0475133133542007, 1.4708639182102907, 1.4821947869981171], [2.3058489599045675, 2.1649572727786506, 1.898522602524727, 1.7414150488604405, 1.6349382332176159, 1.6229285419366921, 1.65248399479374, 1.5150870836464463, 1.5030498117398305, 1.474754299327826, 1.4757377569842491, 1.5503249866947246, 1.4618306942046828, 1.4959661186121072, 1.4809228257768472, 1.4229409216315883, 1.4645211013259403, 1.3840937341094777, 1.4517316992875118, 1.4426905304003672, 1.432516687235255, 1.4864228531053871, 1.4334754541421393, 1.4027157744784264, 1.395122637794276, 1.4224023029303094, 1.4317310934613465, 1.4446649183133604, 1.503780711608328, 1.4617700903279007, 1.5104187187875153, 1.4491136810582155, 1.4818338611323363, 1.5123673912825857, 1.5091017727639264, 1.4836881760579006, 1.5107777559073867, 1.4671283967935356, 1.4727532749722718, 1.462393040110351, 1.5125392379274794, 1.4366357296135774, 1.5400222334892126, 1.528620171698795, 1.5032310041652364, 1.4941550671674644, 1.5122926159269492, 1.5858505835199053, 1.5901931311674178, 1.4878501614947228, 1.486844033951972, 1.5290548285101628, 1.541055033161382, 1.583998760599999, 1.5171787879269594, 1.5404423148768722, 1.530989717526041, 1.7090996807547891, 1.5046218971537937, 1.5912571211529385, 1.569031333467763, 1.542523791455919, 1.5647317277398078, 1.5648210659907882, 1.5787053434712113, 1.5363644304548858, 1.5595231033434533, 1.549932418735164, 1.5664945427019885, 1.5826506424861349, 1.6208977463898386, 1.6327680038039092, 1.6476110212362496, 1.5916729751665881, 1.5486330249506957]]
global_train_loss_algo = [[], [], [], [], []]
