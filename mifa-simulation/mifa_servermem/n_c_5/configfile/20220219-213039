import lenet
import numpy as np

#Generic Hyp
batch_size= 64 #Neural Network batch size
n_rnds= 1500 #Global rounds
tau=5 #Local rounds --> not in use since we use local epochs
total_c= 250 #250 #Total no of clients
no_of_c=[5] #participating clients
local_epochs = 5 
plot_local_train_loss = True


#Cluster
K= 36 #55        #try for 5,10,20. Number of clusters is predetermined for static
cluster = 1
clust_mech = 'static' #'static 

#Model
model_type = 'lenet' #shakespeare_lstm' #'shakespeare_lstm'#'cnnmnist'#'cnnmnist' #'r'
dataset = 'cifar10'

#Plotting
plot_every_n = 20



#Learning rate
algo_lr = {  #lr for each algo, length has to be the same for all algos
    0: [0.01],
    1: [0.08],
    2: [0.01], #0.05
    3: [0.08],
    4: [0.05]
    }

lrfactor = {
    0:1, #factor to reduce lr in scheduler
    1:1,
    2:1,
    3:1,
    4:1
    }

sch_freq = 1 #scheduler every n rounds



#select algos to run
d_algo = {
            #0: "MIFA",
            #1: "UMIFA",
            2: "FedAvg",
            #3: "scaffold",
            #4: "UMIFA static"
        }




#MIFA paper paradigm variables
#p_i min is for the paper's paradigm for client selection, each client is selected with a min prob of 0.2
pi_min = 0.2
sel_client_variablepi = False #variable no of clients selected each round according to pi assigned
enforce_cp_r1 = False #enforce all client part in 1st round


loss_algo = [[2.266605930328369, 0.7268936070986092, 0.8262085914611816, 0.7278584766387939, 0.789262431114912, 0.8328173357248305, 0.4864991550380364, 0.39781104219146074, 0.7963750839233399, 0.6060823075845838, 0.5346481820195914, 0.6540009770914913, 0.6000230658054352, 0.5791857862845063, 0.601682240627706, 0.5190603889152408, 0.5686144001036882, 0.3752458044723608, 0.5238422186486422, 0.5128258825093507, 0.4091419728193433, 0.40845248263329265, 0.3796430809050798, 0.3013287895149552, 0.5125403020903467, 0.5991131212748586, 0.42233779141388367, 0.4361695684376173, 0.5032469877973199, 0.32608761260868047, 0.5282123374938965, 0.3950447229295969, 0.5774009934067726, 0.46566474655643103, 0.3646327123069205, 0.46415614344179623, 0.48778910474386067, 0.2545838783669751, 0.4572430377453565, 0.32971935802372176, 0.3245800571789732, 0.3327472523745382, 0.3493784692324698, 0.32167371020186697, 0.33286477030196693, 0.2957916100276634, 0.349626142103225, 0.39972871131263676, 0.39174779985914937, 0.4350884895399213, 0.3715547561389394, 0.26866615810780786, 0.3496144967258442, 0.32577093903440985, 0.35413724374026057, 0.33965593559667473, 0.32831785692833365, 0.25175643964787014, 0.20672295935451981, 0.19863504536915572, 0.28091858461964875, 0.34502744917088424, 0.268632475467748, 0.3027701299916953, 0.28329219892155383, 0.3964059149939566, 0.2668914383533411, 0.20437563372426668, 0.2600222816795576, 0.1959657436172711, 0.3295389977656305, 0.21123826382681726, 0.2802377519570291, 0.28684747384861115, 0.3034199068276212]]
acc_algo = [[tensor(0.1000), tensor(0.1056), tensor(0.1872), tensor(0.1866), tensor(0.2155), tensor(0.2241), tensor(0.1755), tensor(0.2340), tensor(0.2766), tensor(0.2977), tensor(0.2559), tensor(0.2974), tensor(0.3096), tensor(0.3258), tensor(0.3258), tensor(0.3277), tensor(0.3496), tensor(0.3169), tensor(0.3304), tensor(0.3346), tensor(0.3913), tensor(0.3696), tensor(0.3772), tensor(0.2539), tensor(0.3769), tensor(0.4161), tensor(0.4115), tensor(0.4104), tensor(0.4146), tensor(0.3947), tensor(0.4595), tensor(0.3623), tensor(0.4409), tensor(0.3122), tensor(0.4084), tensor(0.4400), tensor(0.3362), tensor(0.3241), tensor(0.3737), tensor(0.4400), tensor(0.3795), tensor(0.3463), tensor(0.3892), tensor(0.4604), tensor(0.3772), tensor(0.4576), tensor(0.4635), tensor(0.4242), tensor(0.4319), tensor(0.4137), tensor(0.4535), tensor(0.4158), tensor(0.4581), tensor(0.4535), tensor(0.4190), tensor(0.3505), tensor(0.4129), tensor(0.4549), tensor(0.4668), tensor(0.5215), tensor(0.3873), tensor(0.4955), tensor(0.5014), tensor(0.2476), tensor(0.5168), tensor(0.4649), tensor(0.4898), tensor(0.4505), tensor(0.3990), tensor(0.4018), tensor(0.4180), tensor(0.4426), tensor(0.2972), tensor(0.4725), tensor(0.4873)]]
test_loss_algo= [[2.303871118339004, 2.6260714849848656, 2.4120719280971845, 2.409005051205872, 2.182197004366832, 2.2427911735644006, 2.7619217368447857, 2.352934918585856, 2.045297640144445, 1.8935333437221065, 2.3420700191692183, 2.091948390766314, 1.8934061990422049, 1.9135446829401004, 1.8467614757027595, 1.8377963076731203, 1.81701025461695, 1.9897786735729048, 1.9364540470633538, 1.982912877562699, 1.9462405222996024, 1.9037779850564944, 1.7602778787066222, 2.4196130895310906, 1.7387240084872884, 1.6801124120214184, 1.6817812767757732, 1.6299497974905999, 1.7231184479537283, 1.7008798874107895, 1.5081710071320746, 2.0188621388878794, 1.5689433987732906, 2.0384149969003764, 1.698885802250759, 1.5789897722803103, 1.875636939030544, 2.1590435770666523, 1.8913457044370614, 1.6488587286821597, 1.8806824752479603, 2.057405424725478, 1.9556179684438524, 1.5971620978823133, 1.9155669273084897, 1.6665107239583494, 1.5615776093902103, 1.632922878690586, 1.6873853889999875, 1.8008693889447838, 1.5817927653622474, 1.772542264810793, 1.5359481922380485, 1.7144343268339801, 1.7403066537942096, 2.055244419225462, 1.9417891669425236, 1.571626900867292, 1.6192392346205984, 1.3945775001671663, 1.966594428013844, 1.4353576587263945, 1.4407802045724953, 3.4662667186396896, 1.3770995010995561, 1.589984660695313, 1.5800997254195486, 1.7329540920865005, 2.066873349961202, 1.911852010496103, 1.8351701270243166, 1.8370396377174718, 2.6644384291521304, 1.708401631397806, 1.631705492165438]]
global_train_loss_algo = [[]]
