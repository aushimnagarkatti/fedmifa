import lenet
import numpy as np

#Generic Hyp
batch_size= 64 #Neural Network batch size
n_rnds= 2000 #Global rounds
tau=5 #Local rounds --> not in use since we use local epochs
total_c= 250 #Total no of clients
no_of_c=[5] #participating clients
local_epochs = 5 
plot_local_train_loss = True


#Cluster
K= 5        #try for 5,10,20
cluster = 0

#Model
model_type = 'cnnmnist' #'r'
dataset = 'emnist'#cifar10'

#Plotting
plot_every_n = 20



#Learning rate
algo_lr = {  #lr for each algo, length has to be the same for all algos
    0: [0.1],#[1/np.power(10,2.5)],
    1: [0.1],#[1/np.power(10,2)],
    2: [0.1]#[1/np.power(10,2)]
    }

lrfactor = {
    0:0.8, #factor to reduce lr in scheduler
    1:0.8,
    2:0.8
    }

sch_freq = 500 #scheduler every n rounds



#select algos to run
d_algo = {
            0: "MIFA",
            1: "UMIFA",
            2: "FedAvg"
        }




#MIFA paper paradigm variables
#p_i min is for the paper's paradigm for client selection, each client is selected with a min prob of 0.2
pi_min = 0.2
sel_client_variablepi = False #variable no of clients selected each round according to pi assigned
enforce_cp_r1 = False #enforce all client part in 1st round


Loss algo: [[3.7570488293965654, 3.689013651212057, 3.4729205465316775, 3.468511253992717, 3.5814257537523906, 3.3109825909932455, 3.2055269489288327, 3.153968792756398, 3.306111977259318, 3.037113043308258, 2.8374454151789346, 2.683991133371989, 2.6221878919601442, 2.5444319003423055, 2.524659439404806, 2.40232487042745, 2.32368954261144, 2.2541226704915363, 2.585181423505147, 1.7161832547187807, 2.0999083743890123, 1.8980516764322917, 2.1794100210865337, 1.7985494405428568, 1.7538111295700074, 1.8476150205135344, 1.7768184367815654, 1.7406578667958577, 1.6280165032744407, 1.8514258690675098, 1.6753418318430584, 1.4505942366123201, 1.5447857661247255, 1.3251140414873759, 1.2678044921557106, 1.5954098491668702, 1.4554336460828783, 1.2502186316535586, 1.2725183861596243, 1.428702712694804, 1.3432140398025514, 1.3803889018297195, 1.7553498810132346, 1.5384983075459797, 1.2494856019020082, 1.2443643990357718, 1.2622486511071522, 2.0325795057614644, 1.5797835234006246, 1.2645745921929676, 1.3367477633953095, 1.380039554913839, 1.2764460118611656, 1.3427143343289694, 1.4628702923456827, 1.3117426435152688, 0.8698539411624273, 1.2034783607721329, 1.1434359871347746, 0.9861400577227275, 1.1808798786004384, 1.2831016989300648, 1.0672734653949738, 1.1588873020807902, 0.9456722474098205, 1.1028815440336863, 1.301537133852641, 1.0040660989284516, 1.3571199397643408, 0.8879591049750646, 1.1266923654874166, 1.3704001163194577, 0.8955529133478801, 1.004012809753418, 0.9422909157276151, 1.0159325251976647, 1.1769434942801795, 1.0572990682522456, 0.8364884970585506, 1.0456297821203866, 1.2778091825644178, 1.1137762474219004, 1.2752009007930756, 0.9996097680599917, 0.9452830258210498, 1.1740998240311942, 0.8891666489839555, 0.9945880867044131, 0.9567276915311813, 0.9455877103408177, 1.177861493508021, 0.8129729036490122, 1.1040939156214395, 0.9902176173528033, 1.1415300449356438, 0.9232143341749905, 1.0493059957027435, 0.9796731836398443, 1.0765459555784862, 1.0333362232049308], [3.7443326854705807, 2.447966006596883, 1.7181131386756896, 1.7112826259930927, 1.5477030151685078, 0.9828353525002799, 1.2100768624941507, 1.3118885793288548, 1.336316363652547, 1.0143680457274118, 0.9495324616432189, 0.8609811528523762, 1.071011292219162, 1.0021284943421682, 0.7742854507764181, 0.7935304131110509, 0.6895334889118869, 0.6655441318949064, 0.8294533652625979, 0.5417630508343378, 0.8351386590401331, 1.3759276059021552, 1.0784908650815486, 0.8972331546545028, 0.868396862745285, 1.0060414207776387, 0.76351058502992, 0.9884283161163332, 0.7184724759235979, 0.9715824311971664, 0.7251287565628687, 0.6638763199845951, 0.6798480650583903, 0.5403581820229688, 0.5167073280413945, 0.6887955901622772, 0.6060525933653116, 0.5039288287929125, 0.5978918977294649, 0.6534092392921448, 0.6911037069559097, 0.659629974514246, 1.074584175904592, 0.8967027652661006, 0.6484833933909735, 0.6332508466144403, 0.6144637009004751, 1.2042543805440267, 1.0000153015851976, 0.5984647711118062, 0.7206233672698339, 0.8678152861595153, 0.6150570457180341, 0.7020856734116873, 0.8033962117830912, 0.7485384448369344, 0.46761871991120285, 0.5762197638551394, 0.6666943928351007, 0.46565701308846474, 0.8055162304888169, 0.6798734129220246, 0.5529746347665787, 0.6851675879955292, 0.5085943526029586, 0.6099853193759918, 0.7354298855969682, 0.5697596536080043, 0.9072892442544301, 0.4338807076215744, 0.6161081707874934, 0.7044399999020001, 0.5025376663605372, 0.5236038074878355, 0.5333550617694854, 0.5927142755190531, 0.657939196050167, 0.5817231610467036, 0.4459443553288778, 0.5944800085326036, 0.8186889608701071, 0.7178714102904002, 0.7568236242135367, 0.5778126137370154, 0.5627055043379465, 0.6552716179192066, 0.5163977108796438, 0.5766859962046147, 0.48678599159419533, 0.5828820196787516, 0.7521666011810303, 0.4667865944902102, 0.636023745884498, 0.5911147561172644, 0.7870526421070098, 0.52627850454549, 0.5291142097612221, 0.5575141118764877, 0.6618699952363969, 0.6318219697475433], [3.7548482767740885, 2.508978662490845, 1.7069116973876954, 1.7252041165033976, 1.474474467118581, 0.9879654827117917, 1.1663828268845875, 1.4070177380243938, 1.2157854208548862, 1.0037126151323317, 0.9737274561127027, 0.8907204415400823, 1.104556058883667, 0.9619921190738676, 0.7486481500466665, 0.7647873057921727, 0.8243970358371735, 0.6681109027067821, 0.841196163237095, 0.5232465093533198, 0.8502618014613788, 0.9375745676358541, 0.7174723212679381, 0.7507103544076286, 0.7397091779112814, 0.906181325674057, 0.7304087227582932, 0.9329792689283689, 0.6330990353624026, 0.9347126935919127, 0.7223286348581315, 0.6345711112221082, 0.6288636655807495, 0.5794995524485906, 0.4815557244420051, 0.6920319970448812, 0.6273567036961516, 0.49843288603637903, 0.5873356842639901, 0.6761909626722337, 0.6593011019627253, 0.5811143604417642, 0.9354492637316387, 0.8356640492280324, 0.6092363159259161, 0.6007255711754164, 0.5776244127849738, 1.2092214028835295, 0.9744544829527537, 0.6009351488351822, 0.6694153793851534, 0.8162792851130167, 0.6102681040763855, 0.6884154679775237, 0.7359690206845603, 0.7164309656620025, 0.4752263477096956, 0.5668661720554035, 0.6208981568987172, 0.46480569113790987, 0.740461176832517, 0.7249964309980472, 0.5293956173459688, 0.6810606650511424, 0.5113665320475895, 0.6263978828589122, 0.7721714325994253, 0.5605844361583392, 0.8727461492419243, 0.4365402631958325, 0.5923233013550441, 0.7089922248447935, 0.49880604982376103, 0.49526393409570063, 0.4965521300633748, 0.5776367769141991, 0.6121693751414616, 0.5597787640318275, 0.48709612478812536, 0.5369787803192934, 0.7583952982227008, 0.7872630995909373, 0.7296829848090807, 0.6205733714955193, 0.5395448661347231, 0.644077665011088, 0.49558917919794715, 0.5467527955770493, 0.5158331721027691, 0.5624011595050494, 0.7709671838680904, 0.4402328586578369, 0.6614332421620687, 0.8976921962574125, 0.7211014606555303, 0.5538700341582298, 0.5439220747848352, 0.5651660000483195, 0.6621285085280737, 0.6538271778821946]]
Acc algo: [[tensor(0.0312), tensor(0.0156), tensor(0.0156), tensor(0.0312), tensor(0.0312), tensor(0.0312), tensor(0.0312), tensor(0.0312), tensor(0.0469), tensor(0.0469), tensor(0.0312), tensor(0.0312), tensor(0.0469), tensor(0.0781), tensor(0.1094), tensor(0.1406), tensor(0.1406), tensor(0.1250), tensor(0.1719), tensor(0.1875), tensor(0.1562), tensor(0.1875), tensor(0.1719), tensor(0.2500), tensor(0.2500), tensor(0.2812), tensor(0.2969), tensor(0.2969), tensor(0.3594), tensor(0.3281), tensor(0.2969), tensor(0.3125), tensor(0.2969), tensor(0.3281), tensor(0.3125), tensor(0.3750), tensor(0.3750), tensor(0.4219), tensor(0.3281), tensor(0.3125), tensor(0.3594), tensor(0.3750), tensor(0.3906), tensor(0.4375), tensor(0.4531), tensor(0.3750), tensor(0.4062), tensor(0.3906), tensor(0.3594), tensor(0.3438), tensor(0.3281), tensor(0.3594), tensor(0.3750), tensor(0.3750), tensor(0.3750), tensor(0.3438), tensor(0.3281), tensor(0.2969), tensor(0.2656), tensor(0.2500), tensor(0.2812), tensor(0.3125), tensor(0.3594), tensor(0.3594), tensor(0.3906), tensor(0.3906), tensor(0.4062), tensor(0.4531), tensor(0.4375), tensor(0.4062), tensor(0.3906), tensor(0.3750), tensor(0.3438), tensor(0.3594), tensor(0.4062), tensor(0.4062), tensor(0.4062), tensor(0.4062), tensor(0.4219), tensor(0.4375), tensor(0.4062), tensor(0.4062), tensor(0.4062), tensor(0.4375), tensor(0.4219), tensor(0.4375), tensor(0.4375), tensor(0.4219), tensor(0.4062), tensor(0.4375), tensor(0.4844), tensor(0.5000), tensor(0.4844), tensor(0.4531), tensor(0.4375), tensor(0.5000), tensor(0.4844), tensor(0.4531), tensor(0.4531), tensor(0.4531)], [tensor(0.0312), tensor(0.0938), tensor(0.1875), tensor(0.2188), tensor(0.3594), tensor(0.3125), tensor(0.3594), tensor(0.4062), tensor(0.3594), tensor(0.5000), tensor(0.4688), tensor(0.3438), tensor(0.4688), tensor(0.5000), tensor(0.5156), tensor(0.4375), tensor(0.4844), tensor(0.4844), tensor(0.4375), tensor(0.5000), tensor(0.5469), tensor(0.5000), tensor(0.4062), tensor(0.4375), tensor(0.5312), tensor(0.5781), tensor(0.4375), tensor(0.5312), tensor(0.4688), tensor(0.6250), tensor(0.5781), tensor(0.5469), tensor(0.3906), tensor(0.5000), tensor(0.5625), tensor(0.5625), tensor(0.5781), tensor(0.6250), tensor(0.5938), tensor(0.5781), tensor(0.5312), tensor(0.5469), tensor(0.4688), tensor(0.4688), tensor(0.5312), tensor(0.5625), tensor(0.5469), tensor(0.5625), tensor(0.6250), tensor(0.6094), tensor(0.4844), tensor(0.6406), tensor(0.5938), tensor(0.5781), tensor(0.6406), tensor(0.5312), tensor(0.6250), tensor(0.5469), tensor(0.5938), tensor(0.5625), tensor(0.5156), tensor(0.5469), tensor(0.5781), tensor(0.5625), tensor(0.5781), tensor(0.5938), tensor(0.5156), tensor(0.5625), tensor(0.6562), tensor(0.5781), tensor(0.6406), tensor(0.3906), tensor(0.5312), tensor(0.5781), tensor(0.5938), tensor(0.5938), tensor(0.5938), tensor(0.5625), tensor(0.6094), tensor(0.5000), tensor(0.6406), tensor(0.5625), tensor(0.5938), tensor(0.5781), tensor(0.6094), tensor(0.5469), tensor(0.6094), tensor(0.5781), tensor(0.5625), tensor(0.5625), tensor(0.6094), tensor(0.5469), tensor(0.5625), tensor(0.5000), tensor(0.5625), tensor(0.5000), tensor(0.6406), tensor(0.6094), tensor(0.5781), tensor(0.6406)], [tensor(0.0156), tensor(0.2500), tensor(0.2031), tensor(0.2031), tensor(0.4219), tensor(0.2969), tensor(0.3906), tensor(0.4531), tensor(0.4219), tensor(0.5000), tensor(0.4531), tensor(0.3594), tensor(0.3750), tensor(0.5469), tensor(0.5469), tensor(0.3594), tensor(0.5312), tensor(0.4688), tensor(0.5312), tensor(0.3906), tensor(0.5469), tensor(0.5000), tensor(0.5469), tensor(0.5625), tensor(0.4531), tensor(0.5312), tensor(0.4375), tensor(0.4844), tensor(0.5312), tensor(0.6406), tensor(0.5469), tensor(0.6094), tensor(0.5469), tensor(0.5781), tensor(0.5625), tensor(0.6250), tensor(0.6094), tensor(0.6250), tensor(0.5781), tensor(0.4688), tensor(0.6094), tensor(0.5469), tensor(0.5781), tensor(0.5469), tensor(0.5938), tensor(0.5781), tensor(0.6250), tensor(0.5625), tensor(0.5781), tensor(0.5781), tensor(0.5781), tensor(0.5781), tensor(0.6250), tensor(0.6562), tensor(0.6562), tensor(0.6719), tensor(0.6094), tensor(0.6094), tensor(0.5156), tensor(0.5938), tensor(0.4219), tensor(0.6406), tensor(0.6406), tensor(0.6406), tensor(0.4844), tensor(0.5156), tensor(0.5625), tensor(0.5781), tensor(0.6562), tensor(0.6250), tensor(0.5938), tensor(0.3906), tensor(0.4531), tensor(0.6406), tensor(0.5781), tensor(0.6406), tensor(0.6875), tensor(0.6562), tensor(0.5781), tensor(0.4844), tensor(0.6250), tensor(0.6719), tensor(0.6562), tensor(0.7031), tensor(0.6562), tensor(0.7031), tensor(0.5938), tensor(0.6406), tensor(0.7188), tensor(0.5000), tensor(0.5469), tensor(0.5781), tensor(0.7031), tensor(0.6250), tensor(0.6406), tensor(0.5469), tensor(0.5938), tensor(0.5312), tensor(0.6719), tensor(0.6719)]]
test_loss_algo: [[4.110223770141602, 4.086792945861816, 4.112880229949951, 5.270050048828125, 6.467535972595215, 5.474328994750977, 3.9017326831817627, 3.5513691902160645, 3.4836995601654053, 3.4159035682678223, 3.375009059906006, 3.3202295303344727, 3.202605962753296, 2.9486236572265625, 2.7449073791503906, 2.706740140914917, 2.6690382957458496, 2.6072614192962646, 2.5784380435943604, 2.630063533782959, 2.7598118782043457, 2.8056509494781494, 2.770860433578491, 2.7009572982788086, 2.6072845458984375, 2.4971511363983154, 2.402726173400879, 2.289422035217285, 2.187178134918213, 2.183216094970703, 2.203556776046753, 2.185176134109497, 2.1503665447235107, 2.1619601249694824, 2.166351079940796, 2.123232841491699, 2.0047836303710938, 1.939132571220398, 1.9933345317840576, 2.0616819858551025, 2.0590298175811768, 2.0017223358154297, 1.921107530593872, 1.8591958284378052, 1.8431247472763062, 1.8530317544937134, 1.9028412103652954, 2.0085949897766113, 2.1618828773498535, 2.2765986919403076, 2.253763437271118, 2.1193552017211914, 1.958956241607666, 1.8475130796432495, 1.8093761205673218, 1.7907627820968628, 1.8284748792648315, 1.8886834383010864, 1.9557572603225708, 1.997302770614624, 1.994905710220337, 1.9586961269378662, 1.8793962001800537, 1.8152742385864258, 1.8046904802322388, 1.8266502618789673, 1.8636424541473389, 1.92567777633667, 2.0273821353912354, 2.092306137084961, 2.059264898300171, 1.9408398866653442, 1.800731897354126, 1.668623924255371, 1.6474857330322266, 1.7270227670669556, 1.8402936458587646, 1.8769174814224243, 1.8526699542999268, 1.8004367351531982, 1.7834672927856445, 1.7658990621566772, 1.7053227424621582, 1.6569830179214478, 1.6949995756149292, 1.7720003128051758, 1.848134160041809, 1.8518096208572388, 1.7827445268630981, 1.6471740007400513, 1.560073971748352, 1.514037013053894, 1.540624737739563, 1.6028090715408325, 1.6909103393554688, 1.6880383491516113, 1.6371370553970337, 1.6204757690429688, 1.6525923013687134, 1.6599788665771484], [4.450209617614746, 2.6356565952301025, 2.5615270137786865, 2.638093948364258, 1.9498995542526245, 2.5049080848693848, 2.123286724090576, 1.7952773571014404, 1.737497329711914, 1.515580177307129, 1.48668372631073, 2.060075044631958, 2.011657476425171, 1.5091763734817505, 1.5756568908691406, 1.7111836671829224, 1.7111599445343018, 1.4418325424194336, 3.0483720302581787, 1.7205816507339478, 1.4930638074874878, 1.3728917837142944, 2.022498369216919, 1.6186962127685547, 1.5523700714111328, 1.4071989059448242, 1.6420997381210327, 1.23434579372406, 1.8595601320266724, 1.2070965766906738, 1.3455157279968262, 1.2604602575302124, 1.840130090713501, 1.3164613246917725, 1.2967346906661987, 1.362388253211975, 1.1705409288406372, 1.2661216259002686, 1.1273994445800781, 1.4611608982086182, 1.4253060817718506, 1.4116586446762085, 1.7780569791793823, 1.7815278768539429, 1.400850534439087, 1.3888294696807861, 1.419224500656128, 1.3778249025344849, 1.1532701253890991, 1.3043144941329956, 1.64512300491333, 1.2034471035003662, 1.4644252061843872, 1.2673817873001099, 1.1986480951309204, 1.530613660812378, 1.138725996017456, 1.274426817893982, 1.0948588848114014, 1.3647109270095825, 1.3358800411224365, 1.374495267868042, 1.2723673582077026, 1.2907708883285522, 1.5564541816711426, 1.3678302764892578, 1.4098060131072998, 1.3762485980987549, 1.0909435749053955, 1.4227204322814941, 1.1601746082305908, 1.6181284189224243, 1.4228715896606445, 1.30266273021698, 1.3590567111968994, 1.3163317441940308, 1.2365150451660156, 1.481862187385559, 1.350563645362854, 1.4555515050888062, 1.1445831060409546, 1.302319049835205, 1.5292332172393799, 1.5000163316726685, 1.3768291473388672, 1.4788825511932373, 1.1110477447509766, 1.2178337574005127, 1.3184046745300293, 1.3939590454101562, 1.4013768434524536, 1.372402548789978, 1.546743631362915, 1.3911467790603638, 1.335659384727478, 1.3727275133132935, 1.3066831827163696, 1.2068508863449097, 1.3548593521118164, 1.1196790933609009], [4.380284786224365, 2.5517709255218506, 2.614468812942505, 2.5384764671325684, 1.9129772186279297, 2.2639479637145996, 1.8521808385849, 1.876201868057251, 1.6546218395233154, 1.5280002355575562, 1.6641238927841187, 1.8681225776672363, 1.927473545074463, 1.4373319149017334, 1.4168434143066406, 2.04313063621521, 1.6873173713684082, 1.6672621965408325, 1.5940443277359009, 1.8069145679473877, 1.544122576713562, 1.7201557159423828, 1.573378086090088, 1.4010518789291382, 1.862259030342102, 1.4442939758300781, 1.9851019382476807, 1.5449806451797485, 1.678878903388977, 1.3302611112594604, 1.441327691078186, 1.3905717134475708, 1.5697438716888428, 1.4072657823562622, 1.5522456169128418, 1.246124505996704, 1.1749851703643799, 1.1670055389404297, 1.2680613994598389, 1.710889458656311, 1.3600369691848755, 1.2667887210845947, 1.2116343975067139, 1.2906949520111084, 1.3342310190200806, 1.1580021381378174, 1.4893107414245605, 1.415819764137268, 1.255113124847412, 1.296189308166504, 1.086855411529541, 1.3487675189971924, 1.253208875656128, 1.2199292182922363, 1.108434796333313, 1.144166111946106, 1.3268557786941528, 1.3677161931991577, 1.3584810495376587, 1.393596887588501, 1.8593336343765259, 1.2649625539779663, 1.1131118535995483, 1.1171329021453857, 1.8253511190414429, 1.4511674642562866, 1.549907922744751, 1.3864308595657349, 1.114181399345398, 1.2182960510253906, 1.069840431213379, 1.8791255950927734, 1.841091275215149, 1.1210451126098633, 1.272314429283142, 0.976850152015686, 1.1215641498565674, 1.0023691654205322, 1.230154275894165, 1.5755366086959839, 1.0378327369689941, 0.8705161213874817, 1.1888636350631714, 0.8961148858070374, 0.9943363070487976, 0.9344998598098755, 1.1893044710159302, 1.0743776559829712, 0.953157365322113, 1.5336925983428955, 1.3474948406219482, 1.3800575733184814, 0.9561015963554382, 1.0157963037490845, 1.1353193521499634, 1.3160371780395508, 1.1622823476791382, 1.3200465440750122, 1.0008790493011475, 0.9183897972106934]]
global_train_loss_algo: [[], [], []]
