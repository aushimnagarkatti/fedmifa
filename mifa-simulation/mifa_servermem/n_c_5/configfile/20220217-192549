import lenet
import numpy as np

#Generic Hyp
batch_size= 64 #Neural Network batch size
n_rnds= 1000 #Global rounds
tau=5 #Local rounds --> not in use since we use local epochs
total_c= 250 #250 #Total no of clients
no_of_c=[5] #participating clients
local_epochs = 5 
plot_local_train_loss = True


#Cluster
K= 36 #55        #try for 5,10,20. Number of clusters is predetermined for static
cluster = 0
clust_mech = 'static' #'static 

#Model
model_type = 'lenet' #shakespeare_lstm' #'shakespeare_lstm'#'cnnmnist'#'cnnmnist' #'r'
dataset = 'cifar10'

#Plotting
plot_every_n = 50



#Learning rate
algo_lr = {  #lr for each algo, length has to be the same for all algos
    0: [1/np.power(10,2)],
    1: [1/np.power(10,1)],
    2: [1/np.power(10,2)],
    3: [1/np.power(10,1)]
    }

lrfactor = {
    0:1, #factor to reduce lr in scheduler
    1:1,
    2:1,
    3:1
    }

sch_freq = 200 #scheduler every n rounds



#select algos to run
d_algo = {
            0: "MIFA",
            1: "UMIFA",
            2: "FedAvg",
            3: "scaffold"
        }




#MIFA paper paradigm variables
#p_i min is for the paper's paradigm for client selection, each client is selected with a min prob of 0.2
pi_min = 0.2
sel_client_variablepi = False #variable no of clients selected each round according to pi assigned
enforce_cp_r1 = False #enforce all client part in 1st round


loss_algo = [[2.2904007196426392, 1.275859470963478, 1.0557502710819244, 0.7636660607904195, 0.6001002047210932, 0.5687146466295234, 0.5625619745999575, 0.4211935786635149, 0.4799311119690537, 0.4944564594235271, 0.5818450797349215, 0.38286138676106934, 0.4695633040834218, 0.4966872248426079, 0.4044091229373589, 0.45048005748540165, 0.2871603378409054, 0.4447238041087985, 0.23171571279643105, 0.363363762460649], [1.5918323820829392, 0.9068988761305811, 0.7060848066955805, 0.4819041082635522, 0.40581030072644353, 0.3222838030476123, 0.2658466632757336, 0.21949287123170502, 0.33226391805219463, 0.2741034318646416, 0.3056729616969823, 0.17139416928635912, 0.2860917594050989, 0.24937317279633137, 0.20273645938839763, 0.2630390900070779, 0.15380030356231147, 0.2171265270654112, 0.11354363190097501, 0.1949132088996703], [2.291238400936127, 0.9337925839424134, 0.7814293172955514, 0.651892407014966, 0.4943919641524553, 0.4986222141631879, 0.48565721353515984, 0.3687924984507845, 0.4311413996899501, 0.47009909865446387, 0.6039956355467438, 0.3657774613052606, 0.456080957390368, 0.4497850409708917, 0.436306430362165, 0.4417862727865577, 0.2790357481161482, 0.42485152261331677, 0.2826945487549529, 0.3422395129036159], [1.6569264471530913, 0.9690919879078864, 0.9465755547583103, 0.6641376520693303, 0.5377297108620406, 0.6195091277873143, 0.5440646236389876, 0.422306571463123, 0.5479980951920153, 0.5243481310456992, 0.666963842958212, 0.4973496070783586, 0.6436336408555509, 0.5409873584192246, 0.5899092468246817, 0.5629971382021904, 0.49778205055743463, 0.7566192047856749, 0.3396440263139084, 0.4991600357927382]]
acc_algo = [[tensor(0.1406), tensor(0.1562), tensor(0.2656), tensor(0.2031), tensor(0.2500), tensor(0.3281), tensor(0.3594), tensor(0.4219), tensor(0.4219), tensor(0.4219), tensor(0.4375), tensor(0.4219), tensor(0.4688), tensor(0.5000), tensor(0.5469), tensor(0.5312), tensor(0.4688), tensor(0.4531), tensor(0.5469), tensor(0.5469)], [tensor(0.1406), tensor(0.2188), tensor(0.3750), tensor(0.5000), tensor(0.4219), tensor(0.4688), tensor(0.4531), tensor(0.5312), tensor(0.5000), tensor(0.5000), tensor(0.5156), tensor(0.5000), tensor(0.4531), tensor(0.3594), tensor(0.4375), tensor(0.4375), tensor(0.3594), tensor(0.4531), tensor(0.5938), tensor(0.4844)], [tensor(0.1406), tensor(0.0938), tensor(0.2500), tensor(0.4062), tensor(0.3750), tensor(0.2188), tensor(0.4219), tensor(0.3906), tensor(0.5156), tensor(0.3906), tensor(0.4375), tensor(0.4062), tensor(0.5156), tensor(0.3125), tensor(0.4375), tensor(0.2031), tensor(0.3438), tensor(0.3125), tensor(0.4531), tensor(0.3125)], [tensor(0.1406), tensor(0.1719), tensor(0.2812), tensor(0.4375), tensor(0.3906), tensor(0.3594), tensor(0.3594), tensor(0.5000), tensor(0.4531), tensor(0.4062), tensor(0.4219), tensor(0.3906), tensor(0.4062), tensor(0.2188), tensor(0.2969), tensor(0.3281), tensor(0.2656), tensor(0.3281), tensor(0.4844), tensor(0.3125)]]
test_loss_algo= [[2.3038201332092285, 2.7632505893707275, 2.148700714111328, 2.085134506225586, 1.9661903381347656, 1.7299995422363281, 1.6764622926712036, 1.5716896057128906, 1.5339527130126953, 1.510890007019043, 1.449724793434143, 1.39159095287323, 1.3313119411468506, 1.3115326166152954, 1.278878092765808, 1.2575078010559082, 1.2951605319976807, 1.2345327138900757, 1.206445574760437, 1.212453842163086], [2.3038201332092285, 2.3203065395355225, 1.6570476293563843, 1.4361119270324707, 1.6880414485931396, 1.4038289785385132, 1.5630273818969727, 1.3306033611297607, 1.2935283184051514, 1.399878978729248, 1.4986774921417236, 1.5340778827667236, 1.555410623550415, 1.5314505100250244, 1.4875121116638184, 1.730559229850769, 1.608034610748291, 1.5773309469223022, 1.401495099067688, 1.6176544427871704], [2.3038201332092285, 2.959390640258789, 2.077920913696289, 1.7668464183807373, 1.8856847286224365, 1.968626856803894, 1.629785418510437, 1.6331024169921875, 1.6385891437530518, 1.8988405466079712, 1.4820396900177002, 1.610579252243042, 1.4406737089157104, 1.7281827926635742, 1.4394097328186035, 3.361290454864502, 1.8294044733047485, 2.045142889022827, 1.4559558629989624, 1.9409059286117554], [2.3038201332092285, 2.4223439693450928, 1.9126180410385132, 1.8534908294677734, 1.959226131439209, 1.7458168268203735, 1.60787832736969, 1.8166942596435547, 1.8651974201202393, 2.1472856998443604, 1.601341962814331, 1.8159334659576416, 1.7374041080474854, 2.0927507877349854, 1.9880027770996094, 2.733077049255371, 2.0345101356506348, 2.0160880088806152, 1.7920100688934326, 1.79845130443573]]
global_train_loss_algo = [[], [], [], []]
