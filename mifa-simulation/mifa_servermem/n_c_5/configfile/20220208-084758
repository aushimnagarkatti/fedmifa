import lenet
import numpy as np

#Generic Hyp
batch_size= 64 #Neural Network batch size
n_rnds= 1500 #Global rounds
tau=5 #Local rounds --> not in use since we use local epochs
total_c= 250 #Total no of clients
no_of_c=[5] #participating clients
local_epochs = 5 
plot_local_train_loss = False


#Cluster
K= 5        #try for 5,10,20
cluster = 0

#Model
model_type = 'r' #'shakespeare_lstm'#'cnnmnist'#'cnnmnist' #'r'
dataset = 'cifar10' #emnist'#cifar10'

#Plotting
plot_every_n = 50



#Learning rate
algo_lr = {  #lr for each algo, length has to be the same for all algos
    0: [1/np.power(10,2.5)],
    1: [1/np.power(10,2)],
    2: [1/np.power(10,2)]
    }

lrfactor = {
    0:1, #factor to reduce lr in scheduler
    1:1,
    2:1
    }

sch_freq = 200 #scheduler every n rounds



#select algos to run
d_algo = {
            0: "MIFA",
            1: "UMIFA",
            2: "FedAvg"
        }




#MIFA paper paradigm variables
#p_i min is for the paper's paradigm for client selection, each client is selected with a min prob of 0.2
pi_min = 0.2
sel_client_variablepi = False #variable no of clients selected each round according to pi assigned
enforce_cp_r1 = False #enforce all client part in 1st round


Loss algo: [[1.2853925430774689, 0.8840000170469283, 0.6659690854325891, 0.7343383004516364, 0.5552238168567418, 0.5164166105538607, 0.5975251168757677, 0.5108431120216846, 0.4356362022459507, 0.5003871055319905, 0.290461796708405, 0.4190590317826718, 0.45655773576349024, 0.24415348365902903, 0.24223835438489916, 0.33178827934665606, 0.2862523098080419, 0.3239964104257524, 0.2616918172966689, 0.2487571473326534, 0.24815464050217995, 0.10691600103396921, 0.12533347801596392, 0.24229118569754063, 0.11118247558362784, 0.19140796285122633, 0.16398566059418954, 0.0966297582583502, 0.11507446466872354, 0.10471255078213289], [1.7343580070137974, 0.7172686074674129, 0.5065479379799217, 0.5175128645543008, 0.4035076311603188, 0.2618166792485863, 0.38624578683637084, 0.40077145775780076, 0.32384721085196355, 0.34392738872207695, 0.1862363526364788, 0.3146545446920209, 0.31635459871497007, 0.16374859296018257, 0.15567254415189383, 0.21334377182909522, 0.1459921016579028, 0.19300816678674892, 0.1512104258791078, 0.15286690389038995, 0.1432555280366796, 0.07046037671971135, 0.10024678222729562, 0.17292400568025185, 0.11730216572701464, 0.08639773039962165, 0.07533931634796318, 0.08595132373855449, 0.10755455414486277, 0.050822983204270714], [1.6737338003516196, 0.716010630428791, 0.5103203330747783, 0.5608279468119145, 0.41233525443822144, 0.2767763852421194, 0.4233851647563278, 0.330068031847477, 0.30355378980748354, 0.3302093640295788, 0.19149200154468418, 0.34170998828019944, 0.3303150692582131, 0.18571805920655607, 0.2061072011990473, 0.23005855192372113, 0.14928765831748025, 0.1932923997659236, 0.26085049333167265, 0.12830618316191247, 0.1034507008534274, 0.0820787869975902, 0.052180308131501076, 0.07710388682491612, 0.07896739180083387, 0.17132173688616603, 0.06262280298164115, 0.09497869526094292, 0.09913277333391307, 0.09354753792053087]]
Acc algo: [[tensor(0.0625), tensor(0.1094), tensor(0.1875), tensor(0.2969), tensor(0.3281), tensor(0.4219), tensor(0.4375), tensor(0.4688), tensor(0.4844), tensor(0.4531), tensor(0.5000), tensor(0.4844), tensor(0.4844), tensor(0.5312), tensor(0.5312), tensor(0.5000), tensor(0.5312), tensor(0.5469), tensor(0.5781), tensor(0.6094), tensor(0.6562), tensor(0.6406), tensor(0.6406), tensor(0.6719), tensor(0.6406), tensor(0.6875), tensor(0.7031), tensor(0.6875), tensor(0.7344), tensor(0.7188)], [tensor(0.1094), tensor(0.3594), tensor(0.3281), tensor(0.3906), tensor(0.5625), tensor(0.4688), tensor(0.5312), tensor(0.5781), tensor(0.5469), tensor(0.6250), tensor(0.6250), tensor(0.6250), tensor(0.6875), tensor(0.7188), tensor(0.6875), tensor(0.5781), tensor(0.6406), tensor(0.6250), tensor(0.6250), tensor(0.6875), tensor(0.6562), tensor(0.6719), tensor(0.5625), tensor(0.6562), tensor(0.6250), tensor(0.7031), tensor(0.6875), tensor(0.6719), tensor(0.6875), tensor(0.6875)], [tensor(0.1094), tensor(0.1875), tensor(0.2656), tensor(0.3281), tensor(0.4688), tensor(0.4531), tensor(0.5469), tensor(0.4688), tensor(0.4375), tensor(0.5312), tensor(0.5000), tensor(0.5000), tensor(0.6250), tensor(0.6719), tensor(0.5781), tensor(0.4688), tensor(0.6719), tensor(0.3906), tensor(0.6875), tensor(0.6562), tensor(0.6719), tensor(0.6094), tensor(0.5938), tensor(0.6875), tensor(0.6875), tensor(0.7188), tensor(0.7188), tensor(0.6562), tensor(0.7812), tensor(0.7969)]]
test_loss_algo: [[2.5336382389068604, 2.1584625244140625, 2.0034713745117188, 1.8847192525863647, 1.753854513168335, 1.601276159286499, 1.516703486442566, 1.5237175226211548, 1.467469573020935, 1.3554880619049072, 1.3648439645767212, 1.3688888549804688, 1.2998853921890259, 1.2207225561141968, 1.1922014951705933, 1.15738046169281, 1.1234700679779053, 1.1248403787612915, 1.0865598917007446, 1.0559746026992798, 1.0056209564208984, 1.0243746042251587, 0.991664707660675, 0.9788432121276855, 0.9707736372947693, 0.9763079881668091, 0.9578235149383545, 0.9355393052101135, 0.8950660228729248, 0.9591829776763916], [3.6602439880371094, 1.7735422849655151, 1.9283028841018677, 1.682708740234375, 1.3973530530929565, 1.4795541763305664, 1.249879240989685, 1.247168779373169, 1.183274507522583, 1.073377013206482, 1.0275073051452637, 1.1066675186157227, 0.9692715406417847, 0.9777054786682129, 0.9567745923995972, 1.041490077972412, 0.890529215335846, 0.9371625185012817, 0.808527410030365, 0.960425853729248, 0.9367460608482361, 0.9340726733207703, 1.0979074239730835, 1.009610891342163, 0.9913551807403564, 0.9605597853660583, 0.955072820186615, 0.936233639717102, 0.7913418412208557, 0.9775580167770386], [3.7051546573638916, 1.9203828573226929, 2.086890459060669, 2.500117301940918, 1.6082912683486938, 1.728061318397522, 1.5492395162582397, 1.5306638479232788, 1.5334738492965698, 1.3688640594482422, 1.3674286603927612, 1.4529958963394165, 1.310787558555603, 1.0527408123016357, 1.3422728776931763, 1.437535285949707, 1.1002341508865356, 1.8658846616744995, 1.0280134677886963, 0.9431182742118835, 0.9473982453346252, 1.1948829889297485, 1.108780860900879, 0.9839770793914795, 1.019231915473938, 0.9660685062408447, 0.9782291650772095, 1.0704203844070435, 0.8704793453216553, 0.8354279398918152]]
global_train_loss_algo: [[2.467300471137552, 2.0939176113099394, 2.0242436383386404, 2.0425225956665587, 1.821458940768181, 1.618775186941142, 1.5169376064749325, 1.4845369903327863, 1.4370887933484733, 1.4479563894784053, 1.3428279981588769, 1.2532143127887756, 1.2527371917844123, 1.2686719074273658, 1.1700087616510708, 1.1561294457186824, 1.1156412956049986, 1.0261443687979217, 1.0069563600718212, 1.0068277422424472, 0.993972403466549, 0.9296700606108321, 0.9051979318299257, 0.9119228030866979, 0.8675929386445018, 0.7653552624575622, 0.7808059541618123, 0.725413620243292, 0.7440666617334956, 0.6761671017350444], [3.4623637912828293, 1.9118595699520062, 2.220002310355301, 1.6599638285234457, 1.3547284284516063, 1.3395992672961692, 1.2577955767016886, 1.1332766217039065, 1.0342446097632503, 1.0812999330213309, 0.9369884014434522, 0.8975743674256308, 0.8258429876221415, 0.7238339044706291, 0.8588639316351517, 0.9014830292033418, 0.719613178383054, 0.7335710027028838, 0.7056016598058783, 0.7247277076744363, 0.6179325127083323, 0.6397721852030596, 0.6458774819550916, 0.6472978125447812, 0.6442412862844784, 0.5856595459725241, 0.6225388163648298, 0.8527145881939422, 0.5685570196193808, 0.460089093393377], [3.5015110320142466, 2.229310872609658, 1.9292442597391661, 2.2470953001085756, 1.550907801179325, 1.3613557312494653, 1.3487460707764491, 1.3355451349712089, 1.2774598833240207, 1.1256693842465921, 1.219646371081662, 1.0986776236835343, 1.0646659276826913, 0.828349940307305, 0.9441281617297541, 1.0129730182383068, 0.7461727053460563, 1.2167345590298744, 0.7464412479754299, 0.7295730027091473, 0.5863992710552557, 0.7656227243525903, 0.6255328592741886, 0.48864874361878463, 0.7212516932993593, 0.474582444981236, 0.5591352796158218, 0.3679443922494074, 0.5068868273664313, 0.41187190064383894]]
