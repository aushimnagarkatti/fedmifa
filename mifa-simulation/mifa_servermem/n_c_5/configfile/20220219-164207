import lenet
import numpy as np

#Generic Hyp
batch_size= 64 #Neural Network batch size
n_rnds= 1500 #Global rounds
tau=5 #Local rounds --> not in use since we use local epochs
total_c= 250 #250 #Total no of clients
no_of_c=[5] #participating clients
local_epochs = 5 
plot_local_train_loss = True


#Cluster
K= 36 #55        #try for 5,10,20. Number of clusters is predetermined for static
cluster = 1
clust_mech = 'static' #'static 

#Model
model_type = 'lenet' #shakespeare_lstm' #'shakespeare_lstm'#'cnnmnist'#'cnnmnist' #'r'
dataset = 'cifar10'

#Plotting
plot_every_n = 20



#Learning rate
algo_lr = {  #lr for each algo, length has to be the same for all algos
    0: [1/np.power(10,1.5)],
    1: [0.07],
    2: [0.04], #0.05
    3: [0.06],
    4: [0.07]
    }

lrfactor = {
    0:1, #factor to reduce lr in scheduler
    1:1,
    2:1,
    3:1,
    4:1
    }

sch_freq = 1 #scheduler every n rounds



#select algos to run
d_algo = {
            0: "MIFA",
            1: "UMIFA",
            2: "FedAvg",
            3: "scaffold",
            4: "UMIFA static"
        }




#MIFA paper paradigm variables
#p_i min is for the paper's paradigm for client selection, each client is selected with a min prob of 0.2
pi_min = 0.2
sel_client_variablepi = False #variable no of clients selected each round according to pi assigned
enforce_cp_r1 = False #enforce all client part in 1st round


loss_algo = [[2.067584252357483, 0.8674177215165674, 0.9680086743831634, 0.9134296745061874, 0.8897245886921883, 0.8768037116527557, 0.5338796673784965, 0.4036750140809454, 0.8335846853256225, 0.5853332031518221, 0.509696180569008, 0.6213686397299171, 0.5947182069718837, 0.49688482218422003, 0.5072797490097583, 0.4482140947785229, 0.5529833967611194, 0.37735117086791437, 0.4345012361020781, 0.44845071646326684, 0.40162103341892363, 0.3506052773911506, 0.32835808327421545, 0.281859276771429, 0.44237725686281915, 0.49009206198155875, 0.3159942979289917, 0.28322072722199665, 0.3947976315533742, 0.323716261325535, 0.3970180484093725, 0.2620455713849515, 0.44806978791952135, 0.3381129226181656, 0.22628017225211808, 0.2907690514437854, 0.35155787203169897, 0.16494317861745914, 0.2914999059587717, 0.25536669841632825, 0.1795064804541471, 0.24589737418860746, 0.2505418724997435, 0.165314980619587, 0.17346325815771707, 0.12239111186412628, 0.20811528726189862, 0.25772368686040864, 0.23157531887864935, 0.2196276963595301, 0.23460692214335724, 0.19081719924915888, 0.25649818260426394, 0.1935530118038878, 0.17950266180676405, 0.22676930567366074, 0.24778416014742105, 0.13192452363195115, 0.09262444447329472, 0.1009686564077856, 0.18617810344863756, 0.16310277895987382, 0.15525876620174128, 0.1566564155346714, 0.14012188749737106, 0.17646710151806472, 0.1668044591177022, 0.10900495661655443, 0.14957419403439415, 0.09189895728028205, 0.1902691153646447, 0.13136050449320463, 0.1697618414927274, 0.20175479745958, 0.1659830898710061], [1.5936298656463623, 0.6693601841438793, 0.7712141117453575, 0.57290493439883, 0.6033890210837125, 0.6977276314981282, 0.41395211430935885, 0.1995486696437001, 0.5842922013252974, 0.42309321984648707, 0.311937525710091, 0.4262559999071528, 0.46288780139759184, 0.37089913966134186, 0.35070303168380634, 0.23125452887965364, 0.3245295446261298, 0.21525946969632065, 0.2963977019375307, 0.263207219732285, 0.3989287072024308, 0.3281926556886174, 0.19086412643431688, 0.16962456265289802, 0.32896190934465264, 0.21965767299057912, 0.2269230479452017, 0.17411332852600028, 0.17846110046142713, 0.1720417295196603, 0.25840822831960397, 0.13390681421151385, 0.3926001334004104, 0.161190470836591, 0.1922486623705481, 0.1613387945073191, 0.18650899707688948, 0.16244825905587276, 0.1951819423364941, 0.1055901793319208, 0.10429423725960078, 0.09516019863011024, 0.1180941768968478, 0.09688687289017253, 0.1308981727861101, 0.115155955543687, 0.15670104120799805, 0.16265826113640286, 0.11153748659970006, 0.11071932208258657, 0.15215595967412782, 0.10843895954458276, 0.10439445069645445, 0.1138882679597009, 0.09264447051682509, 0.17660198409110306, 0.07976520427386276, 0.10153199196412972, 0.07545281632046681, 0.07856600792089011, 0.08153580754904396, 0.08634771371368513, 0.08715861340698212, 0.09017393938614987, 0.11170715221225691, 0.09391590593411821, 0.18139434771612287, 0.07127157247217837, 0.06650588304311895, 0.07427885871453327, 0.07521041935018728, 0.09910935274026995, 0.08659245467744767, 0.13923396383253023, 0.09598017432668712], [1.9484060138463974, 0.661732844633516, 0.7821358008682728, 0.6218637532740832, 0.7034912561625243, 0.6671235800534486, 0.4017410212825053, 0.285709969123709, 0.6940541182458401, 0.44280272207222876, 0.3776646717032418, 0.46104034481570116, 0.45217981852591044, 0.4457778836973011, 0.43776986483950164, 0.4086147519899532, 0.4170421821903437, 0.3226972503995057, 0.44582007341086866, 0.3614027049479773, 0.3619843916676473, 0.263724071145989, 0.23146596021251753, 0.21426134389766954, 0.34008743017911913, 0.3513124448363669, 0.21749878775051915, 0.24606635477059174, 0.30350900516845286, 0.2584175163631153, 0.28488909875275564, 0.21334837361471726, 0.37912878992035987, 0.24718953471630808, 0.17322864148329248, 0.16897740660235286, 0.25279074383637634, 0.13486109213961756, 0.18793352132430302, 0.2112955329497345, 0.10212602808780502, 0.16596297953801695, 0.17224466579034925, 0.1688185749319382, 0.1341896080947481, 0.13666026303631953, 0.14513746091281066, 0.19586875077853622, 0.1607001378240966, 0.1607878590025939, 0.14248625067877582, 0.11522498855258163, 0.11147680448455503, 0.12740951123618288, 0.1784042941237567, 0.14696248485939575, 0.16010079742991365, 0.11721201445470797, 0.08792191146640108, 0.10961723775748396, 0.08972740781639003, 0.13705802619226232, 0.12623242579778887, 0.09440570560283959, 0.09302185761043803, 0.18290063102089335, 0.11832345351140247, 0.09013009966132814, 0.06404482761514374, 0.10397520097816595, 0.08927416021411774, 0.10829966887453338, 0.17477381615666673, 0.1258847506705206, 0.25219184782006776], [1.662949773669243, 0.686858780970797, 0.8375533500313759, 0.6770112473517658, 0.8185885656252502, 0.8678648580610753, 0.6164279263518984, 0.3544281360437162, 0.8201488046348094, 0.6746516934223473, 0.5214031137526035, 0.6311753467470409, 0.7238523750007152, 0.5660381230339409, 0.6819769562035799, 0.43185081547126175, 0.6179681983031332, 0.5084440187830478, 0.5818404974322766, 0.504854992198525, 0.46574062686413525, 0.470930754467845, 0.4396593760326505, 0.258104213012848, 0.5693875134736299, 0.5938630461320281, 0.4295653182984097, 0.5112324691098183, 0.4204576284997166, 0.3679565839935094, 0.5818578665703534, 0.3914268098771572, 0.5505025870352984, 0.5122730550169944, 0.36599642619490624, 0.4331801947182976, 0.4887752631632611, 0.2464077745564282, 0.4096427162922919, 0.3622771032527089, 0.2762527024094016, 0.341207522302866, 0.35640468468889597, 0.3737314352858812, 0.2511496107745915, 0.25569104655645786, 0.34186406969092786, 0.4697286862597684, 0.47587921483769613, 0.3975776781514287, 0.4157025296729989, 0.2879014599969378, 0.36091831073863434, 0.45413744946010415, 0.29374501943588255, 0.46560089217498896, 0.33417579608969394, 0.24701539784669876, 0.21681485881097612, 0.24010022500413472, 0.300579450649675, 0.28667824160773303, 0.2977994295360986, 0.48353246546583256, 0.3366308085620403, 0.3698697426775471, 0.41176787488628175, 0.23499227856751528, 0.2629772172262892, 0.24651746890231152, 0.38533903184346857, 0.3154223245475441, 0.405008236404974, 0.32710638642311096, 0.3158419576566666], [1.6075367361307145, 0.6212186256720451, 0.8290887833386661, 0.5676124840974808, 0.5821267318725586, 0.7423343849182129, 0.3622568617378602, 0.19920675596658838, 0.61474795229733, 0.41205435281619424, 0.3092602422088385, 0.44117313544265924, 0.47006374496966596, 0.392271383353509, 0.3436386223556474, 0.3271563716651872, 0.34820387122221297, 0.2256485092702496, 0.33716899153776464, 0.2668904164369451, 0.2807098674157169, 0.22661851891782137, 0.15628928244812415, 0.22124214699128064, 0.318863323868718, 0.3357892830204219, 0.21303586390102286, 0.2152307380606726, 0.2787473092996515, 0.17933280469067542, 0.23623522970825434, 0.11455335751175881, 0.327837681057863, 0.2051369308517314, 0.189280612467046, 0.2030708779930137, 0.19508384487256988, 0.20327271928634216, 0.1752292581484653, 0.1510478766164124, 0.09345608446325059, 0.12447188573021777, 0.21986399516579694, 0.09836675669415854, 0.13080232244708895, 0.10278956168354605, 0.16043043825309722, 0.10123111205932218, 0.16408062450267608, 0.17458004736807198, 0.12127235927589937, 0.13190103048022137, 0.21719582047313452, 0.11679266865598037, 0.10547874157637124, 0.15892400785814972, 0.08154772194335237, 0.09687219674020525, 0.07456253405252937, 0.07887894255982246, 0.11231330842820626, 0.18477045345838178, 0.1191511941511999, 0.09835756897111422, 0.10018169571980251, 0.1710747948481003, 0.1283805204456439, 0.07242966954579969, 0.07578599426429719, 0.09297721173782747, 0.08951800044975243, 0.16156904564006253, 0.10977760612498969, 0.3273176857008366, 0.1445469866762869]]
acc_algo = [[tensor(0.1000), tensor(0.1225), tensor(0.1080), tensor(0.1893), tensor(0.2198), tensor(0.2534), tensor(0.2669), tensor(0.2759), tensor(0.3376), tensor(0.3487), tensor(0.3510), tensor(0.3824), tensor(0.4153), tensor(0.4226), tensor(0.4383), tensor(0.4484), tensor(0.4552), tensor(0.4691), tensor(0.4802), tensor(0.4713), tensor(0.4779), tensor(0.4905), tensor(0.5037), tensor(0.5041), tensor(0.5073), tensor(0.5090), tensor(0.5083), tensor(0.5102), tensor(0.5172), tensor(0.5154), tensor(0.5203), tensor(0.5260), tensor(0.5222), tensor(0.5303), tensor(0.5238), tensor(0.5285), tensor(0.5284), tensor(0.5332), tensor(0.5318), tensor(0.5336), tensor(0.5346), tensor(0.5422), tensor(0.5493), tensor(0.5440), tensor(0.5480), tensor(0.5488), tensor(0.5459), tensor(0.5471), tensor(0.5486), tensor(0.5483), tensor(0.5482), tensor(0.5478), tensor(0.5470), tensor(0.5477), tensor(0.5540), tensor(0.5521), tensor(0.5518), tensor(0.5478), tensor(0.5487), tensor(0.5501), tensor(0.5493), tensor(0.5471), tensor(0.5498), tensor(0.5499), tensor(0.5486), tensor(0.5480), tensor(0.5518), tensor(0.5547), tensor(0.5455), tensor(0.5482), tensor(0.5518), tensor(0.5492), tensor(0.5470), tensor(0.5459), tensor(0.5471)], [tensor(0.1000), tensor(0.1069), tensor(0.1851), tensor(0.3410), tensor(0.3544), tensor(0.3957), tensor(0.4399), tensor(0.4635), tensor(0.4299), tensor(0.4950), tensor(0.4976), tensor(0.5010), tensor(0.4896), tensor(0.5098), tensor(0.5148), tensor(0.5157), tensor(0.5119), tensor(0.5194), tensor(0.5293), tensor(0.5157), tensor(0.4783), tensor(0.5253), tensor(0.5100), tensor(0.5289), tensor(0.5310), tensor(0.5242), tensor(0.5254), tensor(0.5332), tensor(0.5364), tensor(0.5325), tensor(0.5381), tensor(0.5344), tensor(0.5272), tensor(0.5388), tensor(0.5374), tensor(0.5394), tensor(0.5352), tensor(0.5317), tensor(0.5336), tensor(0.5407), tensor(0.5297), tensor(0.5402), tensor(0.5318), tensor(0.5364), tensor(0.5367), tensor(0.5371), tensor(0.5296), tensor(0.5384), tensor(0.5378), tensor(0.5395), tensor(0.5264), tensor(0.5346), tensor(0.5346), tensor(0.5362), tensor(0.5306), tensor(0.5338), tensor(0.5329), tensor(0.5344), tensor(0.5334), tensor(0.5371), tensor(0.5357), tensor(0.5367), tensor(0.5407), tensor(0.5344), tensor(0.5410), tensor(0.5309), tensor(0.5329), tensor(0.5432), tensor(0.5430), tensor(0.5389), tensor(0.5453), tensor(0.5423), tensor(0.5401), tensor(0.5407), tensor(0.5362)], [tensor(0.1000), tensor(0.1306), tensor(0.2206), tensor(0.2579), tensor(0.2843), tensor(0.3221), tensor(0.2484), tensor(0.3474), tensor(0.3721), tensor(0.3786), tensor(0.3687), tensor(0.4147), tensor(0.4148), tensor(0.4028), tensor(0.4505), tensor(0.4482), tensor(0.4292), tensor(0.3989), tensor(0.4232), tensor(0.4234), tensor(0.4702), tensor(0.4751), tensor(0.4484), tensor(0.3813), tensor(0.4765), tensor(0.4923), tensor(0.4840), tensor(0.5124), tensor(0.4979), tensor(0.5083), tensor(0.5274), tensor(0.4516), tensor(0.5209), tensor(0.4577), tensor(0.4785), tensor(0.5312), tensor(0.4657), tensor(0.4626), tensor(0.4784), tensor(0.5255), tensor(0.4750), tensor(0.4814), tensor(0.4746), tensor(0.5429), tensor(0.5037), tensor(0.5413), tensor(0.5340), tensor(0.5342), tensor(0.5279), tensor(0.4830), tensor(0.5259), tensor(0.5195), tensor(0.5419), tensor(0.5292), tensor(0.5158), tensor(0.4563), tensor(0.5121), tensor(0.5368), tensor(0.5396), tensor(0.5571), tensor(0.4954), tensor(0.5577), tensor(0.5467), tensor(0.3651), tensor(0.5592), tensor(0.5453), tensor(0.5501), tensor(0.5396), tensor(0.5033), tensor(0.5356), tensor(0.4979), tensor(0.5176), tensor(0.4501), tensor(0.5477), tensor(0.5529)], [tensor(0.1000), tensor(0.1408), tensor(0.2486), tensor(0.3027), tensor(0.3749), tensor(0.3583), tensor(0.2844), tensor(0.3693), tensor(0.3755), tensor(0.4214), tensor(0.3467), tensor(0.4279), tensor(0.4405), tensor(0.4253), tensor(0.4245), tensor(0.4406), tensor(0.4465), tensor(0.4410), tensor(0.4323), tensor(0.4538), tensor(0.4515), tensor(0.4636), tensor(0.4205), tensor(0.3913), tensor(0.4610), tensor(0.4847), tensor(0.4858), tensor(0.4625), tensor(0.4806), tensor(0.5023), tensor(0.5134), tensor(0.4270), tensor(0.5264), tensor(0.4479), tensor(0.4248), tensor(0.5077), tensor(0.4851), tensor(0.4991), tensor(0.4861), tensor(0.5125), tensor(0.4922), tensor(0.4368), tensor(0.4484), tensor(0.5189), tensor(0.4628), tensor(0.4810), tensor(0.5438), tensor(0.5029), tensor(0.5275), tensor(0.4641), tensor(0.5091), tensor(0.4998), tensor(0.5161), tensor(0.4949), tensor(0.5121), tensor(0.4129), tensor(0.4890), tensor(0.4776), tensor(0.5327), tensor(0.5177), tensor(0.5219), tensor(0.5682), tensor(0.5355), tensor(0.3495), tensor(0.5015), tensor(0.5358), tensor(0.5462), tensor(0.5026), tensor(0.5120), tensor(0.5217), tensor(0.5013), tensor(0.4701), tensor(0.4637), tensor(0.5372), tensor(0.5166)], [tensor(0.1000), tensor(0.2386), tensor(0.3101), tensor(0.3740), tensor(0.4063), tensor(0.4188), tensor(0.4372), tensor(0.4571), tensor(0.4710), tensor(0.4820), tensor(0.4986), tensor(0.5014), tensor(0.5065), tensor(0.5043), tensor(0.5076), tensor(0.5006), tensor(0.5052), tensor(0.5039), tensor(0.5161), tensor(0.5139), tensor(0.5182), tensor(0.5123), tensor(0.5194), tensor(0.5158), tensor(0.5190), tensor(0.5263), tensor(0.5251), tensor(0.5284), tensor(0.5244), tensor(0.5242), tensor(0.5307), tensor(0.5271), tensor(0.5290), tensor(0.5202), tensor(0.5301), tensor(0.5106), tensor(0.5219), tensor(0.5230), tensor(0.5272), tensor(0.5342), tensor(0.5316), tensor(0.5353), tensor(0.5266), tensor(0.5362), tensor(0.5354), tensor(0.5348), tensor(0.5388), tensor(0.5374), tensor(0.5278), tensor(0.5358), tensor(0.5323), tensor(0.5298), tensor(0.5244), tensor(0.5348), tensor(0.5367), tensor(0.5400), tensor(0.5324), tensor(0.5318), tensor(0.5261), tensor(0.5285), tensor(0.5376), tensor(0.5286), tensor(0.5427), tensor(0.5375), tensor(0.5328), tensor(0.5394), tensor(0.5411), tensor(0.5479), tensor(0.5366), tensor(0.5355), tensor(0.5415), tensor(0.5322), tensor(0.5258), tensor(0.5319), tensor(0.5326)]]
test_loss_algo= [[2.3044349190535818, 2.6108130102704283, 2.3841263427855863, 2.27557007826058, 2.174575532317921, 2.0236169304817344, 2.040185654998585, 1.918037363678027, 1.8382318680453453, 1.7930319567394863, 1.7427927065806783, 1.6870642452482965, 1.6222915178651263, 1.58073218005478, 1.5370907221630121, 1.5268233688014328, 1.5150883645768378, 1.4939959846484434, 1.4616683812657738, 1.4822956353995451, 1.4666064514476023, 1.4315118713743369, 1.3980622116927128, 1.4036133684170473, 1.3911552808846637, 1.3907650283947113, 1.3813476756120184, 1.3936619173948932, 1.3762915498891455, 1.3862650303324318, 1.3852630474005536, 1.364776974650705, 1.3818888649059708, 1.3733307259857275, 1.370182944710847, 1.3673690599241075, 1.3696577176926241, 1.3743149125651948, 1.3628780553295354, 1.3779335952108833, 1.390173054045173, 1.3501802675283638, 1.3609128267901718, 1.3690215869314353, 1.3600767137138707, 1.3611022735097607, 1.3983306588640638, 1.3693728553261726, 1.3836099961001402, 1.3872480829050586, 1.381796140579661, 1.386569839374275, 1.3899169807221479, 1.4057635380204316, 1.403063491651207, 1.3969245017713803, 1.4161623837841544, 1.4240242994515, 1.4252119808439996, 1.4175293141869223, 1.4273934364318848, 1.422161089766557, 1.4597461421018953, 1.4491078952315506, 1.474357395035446, 1.457671742150738, 1.4643344560246558, 1.462666242745272, 1.4892070046655692, 1.4931981290221974, 1.4838665059417675, 1.4759623469061154, 1.467409597080984, 1.5210709199783907, 1.4699875306171977], [2.3044349190535818, 2.5412629485889604, 2.1557013692369886, 1.7948718405073616, 1.7413573416934651, 1.6331244335053072, 1.5515548522305336, 1.4895963562521966, 1.570315517437686, 1.4001709055748714, 1.4017612152038865, 1.3984168251608586, 1.4170327277699852, 1.3735184274661314, 1.4102167601038695, 1.3836978267712199, 1.3999292759379005, 1.3880702446980082, 1.362338328817088, 1.4611553659864291, 1.5305452483474828, 1.3885223428914502, 1.4865207246914032, 1.4534117962904036, 1.4062118887142012, 1.446387709705693, 1.4380609131163093, 1.4221786351720238, 1.4492600704454313, 1.4416372684916114, 1.4363893908300218, 1.5057251442010235, 1.4924144198180764, 1.4614532870851504, 1.4997633684212994, 1.4463115000421074, 1.4856735908301772, 1.494203500686937, 1.5574766583503432, 1.5291928098459913, 1.4936447067625205, 1.5926774341589327, 1.527426727638123, 1.5524474967057538, 1.5315315563967273, 1.5780982937023138, 1.6082246580700965, 1.5471240156775068, 1.5898065916292228, 1.588257922488413, 1.6410576545508804, 1.623906438138075, 1.5936544624863156, 1.6576441408722264, 1.6830714599342103, 1.5675032089470298, 1.5687126350250973, 1.6352945049856877, 1.5832911289421616, 1.5585359224847928, 1.5757592540637704, 1.6961990594863892, 1.674412135485631, 1.644007882115188, 1.6016225165622249, 1.7412608133000174, 1.6390521913577036, 1.6367873416584768, 1.6344468996023676, 1.6680096775103526, 1.6595912564332318, 1.6451092248509644, 1.7264007246418365, 1.7001984700275834, 1.6360701235236637], [2.3044349190535818, 2.6068041430916757, 2.246968178992059, 2.0662479780282186, 1.8737243102614287, 1.9931448265245766, 2.278163799055063, 2.0625977812299303, 1.8194778618539216, 1.7573963434073576, 2.004240177239582, 1.7593244610318712, 1.6125802803950704, 1.754200099380153, 1.5791956057214434, 1.5629508901553548, 1.6271279754152723, 1.7459925952231048, 1.701884604563379, 1.784663214045725, 1.781990033046455, 1.6768929479987758, 1.6812185041464058, 2.195350737328742, 1.5741392282923317, 1.5770732544030353, 1.5948161585315777, 1.4801434437940075, 1.5940562752401752, 1.4941501981893164, 1.4117651836127991, 1.9260151021799463, 1.4510649829913096, 1.7883428023878936, 1.7310139191378453, 1.5191292956376532, 1.7410994274601055, 1.9043337159855351, 1.7467990635306971, 1.5656398432269978, 1.8363659298344024, 1.7397698536040678, 1.9161172102970683, 1.5531584472413276, 1.7291252848449026, 1.6009378486378179, 1.5539798288588311, 1.5384035702723606, 1.6339233529036212, 1.9238801746611383, 1.633677035380321, 1.6983427492676266, 1.496868636577752, 1.7157368318290467, 1.6701667396126278, 1.9951818847352532, 1.8514924580883827, 1.559701385771393, 1.6521505565400336, 1.480695730941311, 1.840823591894405, 1.465851810707408, 1.5475613357155187, 3.194356473388186, 1.514371605435754, 1.5781942670512352, 1.6624394651431187, 1.6967870369079008, 1.9469572039926129, 1.6792616646760588, 1.905036941455428, 1.7766248504067683, 2.2239205928365138, 1.6526479884317726, 1.5659600473513269], [2.3044349190535818, 2.3986612581143714, 2.1474885682391514, 1.9408223811228564, 1.691303493110997, 1.812196800663213, 1.8827704510111718, 1.8823475981973539, 1.72741994280724, 1.5825093582177618, 2.0968247371114743, 1.6690856081664942, 1.5765833368726596, 1.5908709513913295, 1.6789308004318528, 1.6288772396221283, 1.545065066617006, 1.5694245555598265, 1.6624775661784372, 1.6612529132016904, 1.7277886738443071, 1.615685796282094, 1.7201429567519266, 1.9586116052736902, 1.583796856509652, 1.5440424073273968, 1.535308882309373, 1.6087393229174767, 1.6249066932945495, 1.457169927988842, 1.441285238144504, 1.8562078020375246, 1.4087777661669785, 1.728080574873906, 1.862423258981887, 1.5271342757401194, 1.5211453612442989, 1.5150632622894968, 1.6154609159299522, 1.4747328826576283, 1.4871569887088363, 1.8423688624315202, 1.813908412957647, 1.4385384192132646, 1.7191131600908414, 1.887173010285493, 1.3630657355496838, 1.4995445529366755, 1.5513296620860981, 1.7046499601594962, 1.5159104994148205, 1.5710246821118008, 1.4907306956637436, 1.7831639765174525, 1.5077243751021707, 1.9423699804172394, 1.739410152101213, 1.6265282638513359, 1.4843842459332413, 1.44125263174628, 1.475246398312271, 1.2639278856812008, 1.5154336425149517, 2.6017814851870202, 1.5610528379488902, 1.4621958838906257, 1.4199820794876974, 1.723703890089776, 1.5979047672004456, 1.552327926751155, 1.6586407643214913, 1.9093279314648575, 1.8763630952045416, 1.5420651614286338, 1.5538301475488456], [2.3044349190535818, 2.174160500240933, 1.8604879652618602, 1.7200682110087886, 1.6331874299201237, 1.6133455440496942, 1.570389916183083, 1.5034255062698558, 1.4748856269629897, 1.4377064218946323, 1.4206235788430377, 1.4076150951871447, 1.413002474292828, 1.444354351159114, 1.411517371797258, 1.4409426769633202, 1.4531031535689238, 1.538532379326547, 1.419713901106719, 1.4632408079827668, 1.4306905201286266, 1.4706958053977626, 1.4725256281293881, 1.4288105053506839, 1.4626670525332166, 1.4167728834091478, 1.4346392409057374, 1.4532136218563008, 1.4280026160228025, 1.4829237768604497, 1.5002733746152015, 1.503439996272895, 1.4325293070951086, 1.499722570750364, 1.5212849830366244, 1.6364683398775235, 1.5157054708262159, 1.528272620811584, 1.4888229415674878, 1.529712483002122, 1.5461161303672062, 1.5120277397192208, 1.5534400947534355, 1.595736520685208, 1.5227618570540362, 1.6253363759654342, 1.5520048251577243, 1.534986269701818, 1.5557601049447516, 1.5870387147945964, 1.5235220102747535, 1.6389964336802245, 1.5312347761385001, 1.5506776111900427, 1.6251290789835013, 1.5755058606718755, 1.5566003436495544, 1.588166169300201, 1.6058923757759629, 1.594499903879348, 1.5499501103048872, 1.5715431244509994, 1.6117118934916843, 1.5571029228009996, 1.6415947330225804, 1.559200766739572, 1.575058988704803, 1.6368138736979976, 1.6118945923580486, 1.641761700818493, 1.6320077142897684, 1.5717283570842377, 1.742885525059548, 1.617395389611554, 1.6453661501027976]]
global_train_loss_algo = [[], [], [], [], []]
